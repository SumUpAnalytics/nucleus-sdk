{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import csv, json\n",
    "import time\n",
    "import nucleus_client\n",
    "from nucleus_client.rest import ApiException\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure API host and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = nucleus_client.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-HOST'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create API instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = nucleus_client.DatasetsApi(nucleus_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a small dataset with 10 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add documents to dataset\n",
    "csv_file = 'trump_tweets.csv'\n",
    "dataset = 'dataset_test_delete'   \n",
    "\n",
    "api_instance = nucleus_client.DatasetsApi(nucleus_client.ApiClient(configuration))\n",
    "doc_cnt = 0\n",
    "with open(csv_file, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if doc_cnt < 10:\n",
    "            payload = nucleus_client.Appendjsonparams(dataset=dataset, \n",
    "                                                  language='english', \n",
    "                                                  document={'time': row['time'],\n",
    "                                                            'title': row['title'],\n",
    "                                                            'content': row['content']}\n",
    "                                                 )\n",
    "\n",
    "            try:\n",
    "                response = api_instance.post_append_json_to_dataset(payload)\n",
    "            except ApiException as e:\n",
    "                print(\"Exception when calling DatasetsApi->post_append_json_to_dataset: %s\\n\" % e)\n",
    "        \n",
    "        doc_cnt = doc_cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'list_datasets': \"['dataset_test_delete', 'trump_tweets_test', \"\n",
      "                  \"'trump_tweets_test_1108', 'trump_tweets_test1', \"\n",
      "                  \"'trump_tweets_test111', 'trump_tweets_test2']\"}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api_response = api_instance.get_list_datasets()\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DatasetsApi->get_list_datasets: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'dataset_test_delete',\n",
      " 'detected_language': 'en',\n",
      " 'metadata': '{}',\n",
      " 'num_documents': '10',\n",
      " 'time_range': '[1534582020.0, 1534646340.0]'}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "query = '' # str | Fulltext query, using mysql MATCH boolean query format. (optional)\n",
    "metadata_selection = '' # str | json object of {\\\"metadata_field\\\":[\\\"selected_values\\\"]} (optional)\n",
    "time_period = '' # str | Time period selection (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_dataset_info(dataset, \n",
    "                                                 query=query, \n",
    "                                                 metadata_selection=metadata_selection, \n",
    "                                                 time_period=time_period)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DatasetsApi->get_dataset_info: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': 'Document deleted'}\n"
     ]
    }
   ],
   "source": [
    "payload = nucleus_client.Deletedocumentmodel(dataset=dataset,\n",
    "                                             docid='2') # Deletedocumentmodel | \n",
    "\n",
    "try:\n",
    "    api_response = api_instance.post_delete_document(payload)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DatasetsApi->post_delete_document: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': 'Dataset deleted'}\n",
      "{'list_datasets': \"['trump_tweets_test', 'trump_tweets_test_1108', \"\n",
      "                  \"'trump_tweets_test1', 'trump_tweets_test111', \"\n",
      "                  \"'trump_tweets_test2']\"}\n"
     ]
    }
   ],
   "source": [
    "payload = nucleus_client.Deletedatasetmodel(dataset=dataset) # Deletedatasetmodel | \n",
    "\n",
    "try:\n",
    "    api_response = api_instance.post_delete_dataset(payload)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DatasetsApi->post_delete_dataset: %s\\n\" % e)\n",
    "    \n",
    "# List datasets again to check if the specified dataset has been deleted\n",
    "try:\n",
    "    api_response = api_instance.get_list_datasets()\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DatasetsApi->get_list_datasets: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a full dataset for testing other APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add documents to dataset\n",
    "csv_file = 'trump_tweets.csv'\n",
    "dataset = 'trump_tweets_test'   \n",
    "\n",
    "api_instance = nucleus_client.DatasetsApi(nucleus_client.ApiClient(configuration))\n",
    "\n",
    "with open(csv_file, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        payload = nucleus_client.Appendjsonparams(dataset=dataset, \n",
    "                                                  language='english', \n",
    "                                                  document={'time': row['time'],\n",
    "                                                            'title': row['title'],\n",
    "                                                            'content': row['content']}\n",
    "                                                 )\n",
    "\n",
    "        try:\n",
    "            response = api_instance.post_append_json_to_dataset(payload)\n",
    "        except ApiException as e:\n",
    "            print(\"Exception when calling DatasetsApi->post_append_json_to_dataset: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create API Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = nucleus_client.TopicsApi(nucleus_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of topics from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.16229034123770963, 0.1396182764603817, '\n",
      "                                 '0.1396182764603817, 0.1396182764603817, '\n",
      "                                 '0.1396182764603817, 0.1396182764603817, '\n",
      "                                 '0.1396182764603817]',\n",
      "              'strength': '0.18791715552843313',\n",
      "              'topic': 'trump campaign;lou dobbs;democrats evidence;conflicts '\n",
      "                       'angry;collusion trump;campaign russia;angry democrats'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.1095871118303516, 0.17117535960926852, '\n",
      "                                 '0.1095871118303516, 0.21930083346005658, '\n",
      "                                 '0.1095871118303516, 0.1095871118303516, '\n",
      "                                 '0.17117535960926852]',\n",
      "              'strength': '0.16169879505464493',\n",
      "              'topic': 'donald trump;witch hunt;frame donald;unfortunate '\n",
      "                       'situation;situation decided;rigged witch;decided '\n",
      "                       'frame'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.10003685141509433, 0.10003685141509433, '\n",
      "                                 '0.2, 0.2, 0.2, 0.09996314858490567, '\n",
      "                                 '0.09996314858490567]',\n",
      "              'strength': '0.12934265999548608',\n",
      "              'topic': 'forward special;evidence collusion;dobbs '\n",
      "                       'forward;special counsel;counsel conflicts;special '\n",
      "                       'councel;councel conflicts'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.16903528871340842, 0.19300623964388644, '\n",
      "                                 '0.12407922871220531, 0.12407922871220531, '\n",
      "                                 '0.12407922871220531, 0.12407922871220531, '\n",
      "                                 '0.14164155679388396]',\n",
      "              'strength': '0.13715894403433687',\n",
      "              'topic': 'bruce ohr;christopher steele;fake dossier;time '\n",
      "                       'fusion;helping disgraced;gps fake;disgraced '\n",
      "                       'christopher'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.14285714285714282, 0.14285714285714282, '\n",
      "                                 '0.14285714285714282, 0.14285714285714282, '\n",
      "                                 '0.14285714285714282, 0.14285714285714282, '\n",
      "                                 '0.14285714285714282]',\n",
      "              'strength': '0.08083916249717878',\n",
      "              'topic': 'trump presidency;scandal american;responsible '\n",
      "                       'greatest;mark levin;interfering election;history '\n",
      "                       'interfering;chinese north'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.125, 0.25, 0.125, 0.125, 0.125, 0.125, '\n",
      "                                 '0.125]',\n",
      "              'strength': '0.1010489531214735',\n",
      "              'topic': 'trade deals;unfair trade;tariffs leading;opposed '\n",
      "                       'horrible;leading great;deals opposed;built tariffs'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.14285714285714282, 0.14285714285714282, '\n",
      "                                 '0.14285714285714282, 0.14285714285714282, '\n",
      "                                 '0.14285714285714282, 0.14285714285714282, '\n",
      "                                 '0.14285714285714282]',\n",
      "              'strength': '0.08083916249717878',\n",
      "              'topic': 'trump dossier;phony discredited;notes bruce;emails '\n",
      "                       'notes;doj emails;discredited trump;connection phony'},\n",
      "             {'doc_topic_exposure': '[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, '\n",
      "                                    '0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]',\n",
      "              'keywords_weight': '[0.0006406330255083302, '\n",
      "                                 '0.0006406330255083302, '\n",
      "                                 '0.0006406330255083302, '\n",
      "                                 '0.0006406330255083302, 0.24935936697449168, '\n",
      "                                 '0.24935936697449168, 0.49871873394898336]',\n",
      "              'strength': '0.12115516727126796',\n",
      "              'topic': 'heard heard;heard trump;claims heard;undermine '\n",
      "                       'trump;russians chinese;levin power;greatest scandal'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset\n",
    "query = '(\"Trump\" OR \"president\")' # str | Fulltext query, using mysql MATCH boolean query format. Example, (\\\"word1\\\" OR \\\"word2\\\") AND (\\\"word3\\\" OR \\\"word4\\\") (optional)\n",
    "custom_stop_words = [\"real\",\"hillary\"] # ERRORUNKNOWN | List of stop words. (optional)\n",
    "num_topics = 8 # int | Number of topics to be extracted from the dataset. (optional) (default to 8)\n",
    "metadata_selection =\"\" # str | json object of {\\\"metadata_field\\\":[\\\"selected_values\\\"]} (optional)\n",
    "time_period =\"\"# str | Time period selection (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_topic_api(dataset, \n",
    "                                              query=query, \n",
    "                                              custom_stop_words=custom_stop_words, \n",
    "                                              num_topics=num_topics, \n",
    "                                              metadata_selection=metadata_selection,\n",
    "                                              time_period=time_period)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling TopicsApi->get_topic_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get topic summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'summary': \"[{'title': 'D_Trump2018_8_14_11_21', 'attribute': \"\n",
      "                         \"{'time': 1534270860.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['Lou Dobbs: “This cannot go forward...this Special \"\n",
      "                         'Councel with all of his conflicts with his 17 Angry '\n",
      "                         'Democrats without any evidence of collusion by the '\n",
      "                         \"Trump Campaign and Russia.'], 'sourceid': 73}]\",\n",
      "              'topic': 'trump campaign;lou dobbs;democrats evidence;conflicts '\n",
      "                       'angry;collusion trump;campaign russia;angry democrats'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_16_1_14', 'attribute': \"\n",
      "                         \"{'time': 1534407240.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['We have the unfortunate situation where they then \"\n",
      "                         'decided they were going to frame Donald Trump” '\n",
      "                         \"concerning the Rigged Witch Hunt.'], 'sourceid': \"\n",
      "                         \"46}, {'title': 'D_Trump2018_8_14_12_6', 'attribute': \"\n",
      "                         \"{'time': 1534273560.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['“They were all in on it clear Hillary Clinton and \"\n",
      "                         'FRAME Donald Trump for things he didn’t do.” Gregg '\n",
      "                         'Jarrett on @foxandfriends  If we had a real Attorney '\n",
      "                         'General this Witch Hunt would never have been '\n",
      "                         \"started!'], 'sourceid': 69}]\",\n",
      "              'topic': 'donald trump;witch hunt;frame donald;unfortunate '\n",
      "                       'situation;situation decided;rigged witch;decided '\n",
      "                       'frame'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_14_13_15', 'attribute': \"\n",
      "                         \"{'time': 1534277700.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['Lou Dobbs: “This cannot go forward...this Special \"\n",
      "                         'Counsel with all of his conflicts with his 17 Angry '\n",
      "                         'Democrats without any evidence of collusion by the '\n",
      "                         \"Trump Campaign and Russia.'], 'sourceid': 66}, \"\n",
      "                         \"{'title': 'D_Trump2018_8_14_11_21', 'attribute': \"\n",
      "                         \"{'time': 1534270860.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['Lou Dobbs: “This cannot go forward...this Special \"\n",
      "                         'Councel with all of his conflicts with his 17 Angry '\n",
      "                         'Democrats without any evidence of collusion by the '\n",
      "                         \"Trump Campaign and Russia.'], 'sourceid': 73}]\",\n",
      "              'topic': 'forward special;evidence collusion;dobbs '\n",
      "                       'forward;special counsel;counsel conflicts;special '\n",
      "                       'councel;councel conflicts'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_17_22_29', 'attribute': \"\n",
      "                         \"{'time': 1534570140.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['“Fox News has learned that Bruce Ohr wrote \"\n",
      "                         'Christopher Steele following the firing of James '\n",
      "                         'Comey saying that he was afraid the anti-Trump '\n",
      "                         'Russia probe will be exposed.”  Charles Payne  '\n",
      "                         '@FoxBusiness   How much more does Mueller have to '\n",
      "                         \"see?'], 'sourceid': 13}, {'title': \"\n",
      "                         \"'D_Trump2018_8_14_11_55', 'attribute': {'time': \"\n",
      "                         \"1534272900.0, 'counts': None}, 'sentences': ['Bruce \"\n",
      "                         'Ohr of the “Justice” Department (can you believe he '\n",
      "                         'is still there) is accused of helping disgraced '\n",
      "                         'Christopher Steele “find dirt on Trump.” Ohr’s wife '\n",
      "                         'Nelly was in on the act big time - worked for Fusion '\n",
      "                         \"GPS on Fake Dossier.'], 'sourceid': 70}]\",\n",
      "              'topic': 'bruce ohr;christopher steele;fake dossier;time '\n",
      "                       'fusion;helping disgraced;gps fake;disgraced '\n",
      "                       'christopher'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_16_2_31', 'attribute': \"\n",
      "                         \"{'time': 1534411860.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['Mark Levin “When they had power they didn’t stop \"\n",
      "                         'the Russians the Chinese the North Koreans they '\n",
      "                         'funded the Iranians  are responsible for the '\n",
      "                         'greatest scandal in American history by interfering '\n",
      "                         'with our election  trying to undermine the Trump '\n",
      "                         \"Campaign and Trump Presidency.”'], 'sourceid': 43}]\",\n",
      "              'topic': 'trump presidency;scandal american;responsible '\n",
      "                       'greatest;mark levin;interfering election;history '\n",
      "                       'interfering;chinese north'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_15_15_4', 'attribute': \"\n",
      "                         \"{'time': 1534370640.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['Our Country was built on Tariffs and Tariffs are \"\n",
      "                         'now leading us to great new Trade Deals - as opposed '\n",
      "                         'to the horrible and unfair Trade Deals that I '\n",
      "                         \"inherited as your President.'], 'sourceid': 50}]\",\n",
      "              'topic': 'trade deals;unfair trade;tariffs leading;opposed '\n",
      "                       'horrible;leading great;deals opposed;built tariffs'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_16_23_53', 'attribute': \"\n",
      "                         \"{'time': 1534488780.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['DOJ’s Emails  Notes show Bruce Ohr’s connection to \"\n",
      "                         \"(phony  discredited) Trump Dossier.'], 'sourceid': \"\n",
      "                         '31}]',\n",
      "              'topic': 'trump dossier;phony discredited;notes bruce;emails '\n",
      "                       'notes;doj emails;discredited trump;connection phony'},\n",
      "             {'summary': \"[{'title': 'D_Trump2018_8_16_2_31', 'attribute': \"\n",
      "                         \"{'time': 1534411860.0, 'counts': None}, 'sentences': \"\n",
      "                         \"['Mark Levin “When they had power they didn’t stop \"\n",
      "                         'the Russians the Chinese the North Koreans they '\n",
      "                         'funded the Iranians  are responsible for the '\n",
      "                         'greatest scandal in American history by interfering '\n",
      "                         'with our election  trying to undermine the Trump '\n",
      "                         \"Campaign and Trump Presidency.”'], 'sourceid': 43}]\",\n",
      "              'topic': 'heard heard;heard trump;claims heard;undermine '\n",
      "                       'trump;russians chinese;levin power;greatest scandal'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "query = '(\"Trump\" OR \"president\")' # str | Fulltext query, using mysql MATCH boolean query format. Example, (\\\"word1\\\" OR \\\"word2\\\") AND (\\\"word3\\\" OR \\\"word4\\\") (optional)\n",
    "custom_stop_words = [\"real\",\"hillary\"] # ERRORUNKNOWN | List of stop words. (optional)\n",
    "num_topics = 8 # int | Number of topics to be extracted from the dataset. (optional) (default to 8)\n",
    "num_keywords = 8 # int | Number of keywords per topic that is extracted from the dataset. (optional) (default to 8)\n",
    "summary_length = 6 # int | The maximum number of bullet points a user wants to see in each topic summary. (optional) (default to 6)\n",
    "context_amount = 0 # int | The number of sentences surrounding key summary sentences in the documents that they come from. (optional) (default to 0)\n",
    "num_docs = 20 # int | The maximum number of key documents to use for summarization. (optional) (default to 20)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, \\\"docid1, docid2, ..., docidN\\\"  (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_topic_summary_api(dataset, \n",
    "                                                      query=query, \n",
    "                                                      custom_stop_words=custom_stop_words, \n",
    "                                                      num_topics=num_topics, \n",
    "                                                      num_keywords=num_keywords, \n",
    "                                                      summary_length=summary_length, \n",
    "                                                      context_amount=context_amount, \n",
    "                                                      num_docs=num_docs)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling TopicsApi->get_topic_summary_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get topic sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'document_scores': '[[0.08550935756808034, 0.05408086623457808, '\n",
      "                                 '0.4302048880986708, 0.4302048880986708]]',\n",
      "              'document_sentiments': '[-0.5, -0.3, -0.3333333333333333, '\n",
      "                                     '-0.16666666666666666]',\n",
      "              'sentiment': '-0.27408138270374893',\n",
      "              'strength': '0.18791715552843313',\n",
      "              'topic': 'trump campaign;lou dobbs;democrats evidence;conflicts '\n",
      "                       'angry;collusion trump;campaign russia;angry democrats'},\n",
      "             {'document_scores': '[[0.5396119094739888, 0.24745877601068508, '\n",
      "                                 '0.1265079394077274, 0.08642137510759884]]',\n",
      "              'document_sentiments': '[-0.375, -0.3333333333333333, '\n",
      "                                     '-0.2857142857142857, -0.4]',\n",
      "              'sentiment': '-0.3555544003110787',\n",
      "              'strength': '0.16169879505464493',\n",
      "              'topic': 'donald trump;witch hunt;frame donald;unfortunate '\n",
      "                       'situation;situation decided;rigged witch;decided '\n",
      "                       'frame'},\n",
      "             {'document_scores': '[[0.500046064268868, 0.49995393573113206]]',\n",
      "              'document_sentiments': '[-0.3333333333333333, '\n",
      "                                     '-0.16666666666666666]',\n",
      "              'sentiment': '-0.25000767737814467',\n",
      "              'strength': '0.12934265999548608',\n",
      "              'topic': 'forward special;evidence collusion;dobbs '\n",
      "                       'forward;special counsel;counsel conflicts;special '\n",
      "                       'councel;councel conflicts'},\n",
      "             {'document_scores': '[[0.19683763491762551, 0.15642812549274285, '\n",
      "                                 '0.557812119558343, 0.08892212003128878]]',\n",
      "              'document_sentiments': '[-0.1, -0.2222222222222222, '\n",
      "                                     '-0.3157894736842105, -0.4]',\n",
      "              'sentiment': '-0.2661656128193351',\n",
      "              'strength': '0.13715894403433687',\n",
      "              'topic': 'bruce ohr;christopher steele;fake dossier;time '\n",
      "                       'fusion;helping disgraced;gps fake;disgraced '\n",
      "                       'christopher'},\n",
      "             {'document_scores': '[[1.0]]',\n",
      "              'document_sentiments': '[-0.3]',\n",
      "              'sentiment': '-0.3',\n",
      "              'strength': '0.08083916249717878',\n",
      "              'topic': 'trump presidency;scandal american;responsible '\n",
      "                       'greatest;mark levin;interfering election;history '\n",
      "                       'interfering;chinese north'},\n",
      "             {'document_scores': '[[1.0]]',\n",
      "              'document_sentiments': '[-0.42857142857142855]',\n",
      "              'sentiment': '-0.42857142857142855',\n",
      "              'strength': '0.1010489531214735',\n",
      "              'topic': 'trade deals;unfair trade;tariffs leading;opposed '\n",
      "                       'horrible;leading great;deals opposed;built tariffs'},\n",
      "             {'document_scores': '[[1.0]]',\n",
      "              'document_sentiments': '[-0.2222222222222222]',\n",
      "              'sentiment': '-0.2222222222222222',\n",
      "              'strength': '0.08083916249717878',\n",
      "              'topic': 'trump dossier;phony discredited;notes bruce;emails '\n",
      "                       'notes;doj emails;discredited trump;connection phony'},\n",
      "             {'document_scores': '[[0.0009372291347064687, '\n",
      "                                 '0.9990627708652935]]',\n",
      "              'document_sentiments': '[-0.3, -0.25]',\n",
      "              'sentiment': '-0.2500468614567353',\n",
      "              'strength': '0.12115516727126796',\n",
      "              'topic': 'heard heard;heard trump;claims heard;undermine '\n",
      "                       'trump;russians chinese;levin power;greatest scandal'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "query = '(\"Trump\" OR \"president\")' # str | Fulltext query, using mysql MATCH boolean query format. Example, (\\\"word1\\\" OR \\\"word2\\\") AND (\\\"word3\\\" OR \\\"word4\\\") (optional)\n",
    "custom_stop_words = [\"real\",\"hillary\"] # ERRORUNKNOWN | List of stop words. (optional)\n",
    "num_topics = 8 # int | Number of topics to be extracted from the dataset. (optional) (default to 8)\n",
    "num_keywords = 8 # int | Number of keywords per topic that is extracted from the dataset. (optional) (default to 8)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, \\\"docid1, docid2, ..., docidN\\\"  (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_topic_sentiment_api(dataset, \n",
    "                                                        query=query, \n",
    "                                                        custom_stop_words=custom_stop_words, \n",
    "                                                        num_topics=num_topics, \n",
    "                                                        num_keywords=num_keywords)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling TopicsApi->get_topic_sentiment_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get topic consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'consensus': '1.0',\n",
      "              'strength': '0.18791715552843313',\n",
      "              'topic': 'trump campaign;lou dobbs;democrats evidence;conflicts '\n",
      "                       'angry;collusion trump;campaign russia;angry democrats'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.16169879505464493',\n",
      "              'topic': 'donald trump;witch hunt;frame donald;unfortunate '\n",
      "                       'situation;situation decided;rigged witch;decided '\n",
      "                       'frame'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.12934265999548608',\n",
      "              'topic': 'forward special;evidence collusion;dobbs '\n",
      "                       'forward;special counsel;counsel conflicts;special '\n",
      "                       'councel;councel conflicts'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.13715894403433687',\n",
      "              'topic': 'bruce ohr;christopher steele;fake dossier;time '\n",
      "                       'fusion;helping disgraced;gps fake;disgraced '\n",
      "                       'christopher'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.08083916249717878',\n",
      "              'topic': 'trump presidency;scandal american;responsible '\n",
      "                       'greatest;mark levin;interfering election;history '\n",
      "                       'interfering;chinese north'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.1010489531214735',\n",
      "              'topic': 'trade deals;unfair trade;tariffs leading;opposed '\n",
      "                       'horrible;leading great;deals opposed;built tariffs'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.08083916249717878',\n",
      "              'topic': 'trump dossier;phony discredited;notes bruce;emails '\n",
      "                       'notes;doj emails;discredited trump;connection phony'},\n",
      "             {'consensus': '1.0',\n",
      "              'strength': '0.12115516727126796',\n",
      "              'topic': 'heard heard;heard trump;claims heard;undermine '\n",
      "                       'trump;russians chinese;levin power;greatest scandal'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "query = '(\"Trump\" OR \"president\")' # str | Fulltext query, using mysql MATCH boolean query format. Example, (\\\"word1\\\" OR \\\"word2\\\") AND (\\\"word3\\\" OR \\\"word4\\\") (optional)\n",
    "custom_stop_words = [\"real\",\"hillary\"] # ERRORUNKNOWN | List of stop words. (optional)\n",
    "num_topics = 8 # int | Number of topics to be extracted from the dataset. (optional) (default to 8)\n",
    "num_keywords = 8 # int | Number of keywords per topic that is extracted from the dataset. (optional) (default to 8)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, \\\"docid1, docid2, ..., docidN\\\"  (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_topic_consensus_api(dataset, \n",
    "                                                        query=query, \n",
    "                                                        custom_stop_words=custom_stop_words, \n",
    "                                                        num_topics=num_topics, \n",
    "                                                        num_keywords=num_keywords)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling TopicsApi->get_topic_consensus_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create API instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_instance = nucleus_client.DocumentsApi(nucleus_client.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get document information without content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'attribute': {'author': None,\n",
      "                            'source': None,\n",
      "                            'time': '1534582020.0'},\n",
      "              'sourceid': '10',\n",
      "              'title': 'D_Trump2018_8_18_1_47'},\n",
      "             {'attribute': {'author': None,\n",
      "                            'source': None,\n",
      "                            'time': '1534581960.0'},\n",
      "              'sourceid': '11',\n",
      "              'title': 'D_Trump2018_8_18_1_46'},\n",
      "             {'attribute': {'author': None,\n",
      "                            'source': None,\n",
      "                            'time': '1534581420.0'},\n",
      "              'sourceid': '12',\n",
      "              'title': 'D_Trump2018_8_18_1_37'},\n",
      "             {'attribute': {'author': None,\n",
      "                            'source': None,\n",
      "                            'time': '1534534680.0'},\n",
      "              'sourceid': '20',\n",
      "              'title': 'D_Trump2018_8_17_12_38'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "doc_titles = ['D_Trump2018_8_18_1_47']   # str | The title of the document to retrieve. Example: \\\" \\\"title 1\\\" \\\"  (optional)\n",
    "doc_ids = ['11', '12', '20']      # int | The docid of the document to retrieve. Example: \\\"docid1\\\"  (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_doc_info(dataset, doc_titles=doc_titles, doc_ids=doc_ids)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DocumentsApi->get_doc_info: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display document details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'attribute': {'author': None,\n",
      "                            'source': None,\n",
      "                            'time': '1534582020.0'},\n",
      "              'content': ' financial gain is a Federal Gratuity Statute '\n",
      "                         'Violation Bribery Statute Violation Honest Services '\n",
      "                         'Violation all Major Crimes because the DOJ is run by '\n",
      "                         'BLANK Jeff Sessions ”  Gregg Jarrett. So when does '\n",
      "                         'Mueller do what must be done? Probably never! '\n",
      "                         '@FoxNews',\n",
      "              'sourceid': '10',\n",
      "              'title': 'D_Trump2018_8_18_1_47'},\n",
      "             {'attribute': {'author': None,\n",
      "                            'source': None,\n",
      "                            'time': '1534581960.0'},\n",
      "              'content': '“Bruce Ohr of DOJ is in legal jeopardy it’s '\n",
      "                         'astonishing that he’s still employed. Bruce  Nelly '\n",
      "                         'Ohr’s bank account is getting fatter  fatter because '\n",
      "                         'of the Dossier that they are both peddling. He '\n",
      "                         'doesn’t disclose it under Fed Regs. Using your '\n",
      "                         'Federal office for personal ',\n",
      "              'sourceid': '11',\n",
      "              'title': 'D_Trump2018_8_18_1_46'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "doc_titles = ['D_Trump2018_8_18_1_47']   # str | The title of the document to retrieve. Example: \\\" \\\"title 1\\\" \\\"  (optional)\n",
    "doc_ids = ['11']      # int | The docid of the document to retrieve. Example: \\\"docid1\\\"  (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_doc_display(dataset, doc_titles=doc_titles, doc_ids=doc_ids)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DocumentsApi->get_doc_display_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get document recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534270860.0'},\n",
      "                                   'sourceid': '73',\n",
      "                                   'title': 'D_Trump2018_8_14_11_21'},\n",
      "                                  {'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534277700.0'},\n",
      "                                   'sourceid': '66',\n",
      "                                   'title': 'D_Trump2018_8_14_13_15'}],\n",
      "              'topic': 'trump campaign;lou dobbs;democrats evidence;conflicts '\n",
      "                       'angry;collusion trump;campaign russia;angry democrats'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534273560.0'},\n",
      "                                   'sourceid': '69',\n",
      "                                   'title': 'D_Trump2018_8_14_12_6'},\n",
      "                                  {'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534407240.0'},\n",
      "                                   'sourceid': '46',\n",
      "                                   'title': 'D_Trump2018_8_16_1_14'}],\n",
      "              'topic': 'donald trump;witch hunt;frame donald;unfortunate '\n",
      "                       'situation;situation decided;rigged witch;decided '\n",
      "                       'frame'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534270860.0'},\n",
      "                                   'sourceid': '73',\n",
      "                                   'title': 'D_Trump2018_8_14_11_21'},\n",
      "                                  {'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534277700.0'},\n",
      "                                   'sourceid': '66',\n",
      "                                   'title': 'D_Trump2018_8_14_13_15'}],\n",
      "              'topic': 'forward special;evidence collusion;dobbs '\n",
      "                       'forward;special counsel;counsel conflicts;special '\n",
      "                       'councel;councel conflicts'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534570140.0'},\n",
      "                                   'sourceid': '13',\n",
      "                                   'title': 'D_Trump2018_8_17_22_29'},\n",
      "                                  {'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534272900.0'},\n",
      "                                   'sourceid': '70',\n",
      "                                   'title': 'D_Trump2018_8_14_11_55'}],\n",
      "              'topic': 'bruce ohr;christopher steele;fake dossier;time '\n",
      "                       'fusion;helping disgraced;gps fake;disgraced '\n",
      "                       'christopher'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534411860.0'},\n",
      "                                   'sourceid': '43',\n",
      "                                   'title': 'D_Trump2018_8_16_2_31'}],\n",
      "              'topic': 'trump presidency;scandal american;responsible '\n",
      "                       'greatest;mark levin;interfering election;history '\n",
      "                       'interfering;chinese north'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534370640.0'},\n",
      "                                   'sourceid': '50',\n",
      "                                   'title': 'D_Trump2018_8_15_15_4'}],\n",
      "              'topic': 'trade deals;unfair trade;tariffs leading;opposed '\n",
      "                       'horrible;leading great;deals opposed;built tariffs'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534488780.0'},\n",
      "                                   'sourceid': '31',\n",
      "                                   'title': 'D_Trump2018_8_16_23_53'}],\n",
      "              'topic': 'trump dossier;phony discredited;notes bruce;emails '\n",
      "                       'notes;doj emails;discredited trump;connection phony'},\n",
      "             {'recommendations': [{'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534411860.0'},\n",
      "                                   'sourceid': '43',\n",
      "                                   'title': 'D_Trump2018_8_16_2_31'},\n",
      "                                  {'attribute': {'author': None,\n",
      "                                                 'source': None,\n",
      "                                                 'time': '1534205640.0'},\n",
      "                                   'sourceid': '86',\n",
      "                                   'title': 'D_Trump2018_8_13_17_14'}],\n",
      "              'topic': 'heard heard;heard trump;claims heard;undermine '\n",
      "                       'trump;russians chinese;levin power;greatest scandal'}]}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "query = '(\"Trump\" OR \"president\")' # str | Fulltext query, using mysql MATCH boolean query format. Example, (\\\"word1\\\" OR \\\"word2\\\") AND (\\\"word3\\\" OR \\\"word4\\\") (optional)\n",
    "custom_stop_words = [\"real\",\"hillary\"] # ERRORUNKNOWN | List of stop words. (optional)\n",
    "num_topics = 8 # int | Number of topics to be extracted from the dataset. (optional) (default to 8)\n",
    "num_keywords = 8 # int | Number of keywords per topic that is extracted from the dataset. (optional) (default to 8)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, \\\"docid1, docid2, ..., docidN\\\"  (optional)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_doc_recommend_api(dataset, \n",
    "                                                      query=query, \n",
    "                                                      custom_stop_words=custom_stop_words, \n",
    "                                                      num_topics=num_topics, \n",
    "                                                      num_keywords=num_keywords)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DocumentsApi->get_doc_recommend_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get document summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_title': 'D_Trump2018_8_15_15_4',\n",
      " 'summary': {'sentences': \"['Our Country was built on Tariffs and Tariffs are \"\n",
      "                          'now leading us to great new Trade Deals - as '\n",
      "                          'opposed to the horrible and unfair Trade Deals that '\n",
      "                          \"I inherited as your President.', 'Other Countries \"\n",
      "                          'should not be allowed to come in and steal the '\n",
      "                          \"wealth of our great U.S.A. No longer!']\",\n",
      "             'sourceid': '50'}}\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset # str | Dataset name.\n",
    "doc_title = 'D_Trump2018_8_15_15_4' # str | The title of the document to be summarized.\n",
    "custom_stop_words = [\"real\",\"hillary\"] # ERRORUNKNOWN | List of stop words. (optional)\n",
    "summary_length = 6 # int | The maximum number of bullet points a user wants to see in the document summary. (optional) (default to 6)\n",
    "context_amount = 0 # int | The number of sentences surrounding key summary sentences in the documents that they come from. (optional) (default to 0)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.get_doc_summary_api(dataset, doc_title, custom_stop_words=custom_stop_words, summary_length=summary_length, context_amount=context_amount)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling DocumentsApi->get_doc_summary_api: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
