{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  Training a Content Classifier - Nucleus APIs Use Cases</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  SumUp Analytics, Proprietary & Confidential</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  Disclaimers and Terms of Service available at www.sumup.ai</center></h1>\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## Objective: \n",
    "-\tDevelop an automated content classification model in social-media or gaming chatroom\n",
    "\n",
    "**In its current version, SumUp contrast analysis works comparing two categories against each other, where the user defines what the two categories are.**\n",
    "\n",
    "## Data:\n",
    "-\tA labeled corpus of posts from a social media or gaming platform\n",
    " -     You can have multiple labels in your corpus, but the algorithms will deal with two labels at a time when learning / predicting\n",
    " \n",
    " \n",
    " -     Illustrative labels for low-quality content detection: **\"Violence\", \"Drugs\", \"Pornographic\", \"Religiously Sensitive\", \"Politically Sensitive\", \"Scam\", \"Clickbait\", \"Fake\", \"All clear\"**\n",
    "\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\tDataset creation API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files leverages api_instance.post_upload_file with parallel execution to speed-up the dataset creation\n",
    "\n",
    "\n",
    "-\tContrasted Topic Modeling API\n",
    " - \t*api_instance.post_topic_contrast_api(payload)*\n",
    "\n",
    "\n",
    "-\tDocuments Classification API\n",
    " - \t*api_instance.post_doc_classify_api(payload)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach:\n",
    "\n",
    "### 1.\tDataset Preparation\n",
    "-\tCreate a Nucleus dataset containing all relevant documents\n",
    "\n",
    "\n",
    "-   We assume that the data is stored in a csv file. A similar code could be built to inject from a database table. There are some requirements on the name of data and metadata fields passed to the API to create a dataset\n",
    "\n",
    "\n",
    "    - Illustrative template for the data uploaded: [\"author\", \"label\", \"time\", \"content\", \"title\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "\n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-SERVER-HOSTNAME'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'\n",
    "\n",
    "# Create API instance\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'social-media.csv'\n",
    "dataset = 'social-media'# str | Destination dataset where the file will be inserted.\n",
    "\n",
    "with open(csv_file, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    json_props = nucleus_helper.upload_jsons(api_instance, dataset, reader, processes=4)\n",
    "    \n",
    "    total_size = 0\n",
    "    total_jsons = 0\n",
    "    for jp in json_props:\n",
    "        total_size += jp.size\n",
    "        total_jsons += 1\n",
    "        \n",
    "    print(total_jsons, 'JSON records (', total_size, 'bytes) appended to', dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classifier's Training and Validation\n",
    "\n",
    "-     In this example, we rely on the OLID dataset, which can be obtained from the authors: https://scholar.harvard.edu/malmasi/olid.\n",
    "\n",
    "\n",
    "-     Each objectionable content task is dealt with one at a time\n",
    "\n",
    "\n",
    "-     For each task, a contrasting topic is extracted on the training set and evaluated on the validation set, in order to determine an optimal length/profile of that contrasting topic\n",
    "\n",
    "\n",
    "-     The optimal configuration is finally applied to a test set to derive out-of-sample performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_variables = False # fixed\n",
    "custom_stop_words = []\n",
    "\n",
    "threshold_grid = np.linspace(100, 1000, 50) # Range of values for the hyper-parameter 'num_keywords'\n",
    "perf_grid = []\n",
    "granular_results = {\"Accuracy\":[], \"Recall\":[], \"Precision\":[], \"F1\":[], \"Document_set\":[]}\n",
    "\n",
    "for j in range(3):\n",
    "    if j == 0:\n",
    "        test_set = \"OLID_test_a\"\n",
    "        my_values = ['subtask_a', \"OFF\", \"NOT\"] # offensive and ok\n",
    "    elif j == 1:\n",
    "        test_set = \"OLID_test_b\"\n",
    "        my_values = ['subtask_b', \"UNT\", \"TIN\"] # untargeted and targeted offense\n",
    "    elif j == 2:\n",
    "        test_set = \"OLID_test_c\"\n",
    "        my_values = ['subtask_c', \"GRP\", \"OTH\"] # individual, group, other (IND|GRP|OTH)\n",
    "\n",
    "    metadata_selection = {my_values[0]: [my_values[1], my_values[2]]} \n",
    "\n",
    "    # parameter sensitivity, we max accuracy\n",
    "    optimal_num_keywords = 0.\n",
    "    running_best = 0.\n",
    "    for k in range(len(threshold_grid)):\n",
    "        num_keywords = threshold_grid[k]\n",
    "        try:\n",
    "            payload = nucleus_api.TopicContrastModel(dataset='OLID_train', \n",
    "                                                    metadata_selection=metadata_selection,\n",
    "                                                    num_keywords=num_keywords,\n",
    "                                                    syntax_variables=syntax_variables,\n",
    "                                                    custom_stop_words=custom_stop_words,\n",
    "                                                    remove_redundancies=False)\n",
    "            api_response = api_instance.post_topic_contrast_api(payload)\n",
    "\n",
    "            fixed_topics = {'weights': api_response.result.keywords_weight, 'keywords': api_response.result.keywords}\n",
    "            classifier_config = {'coefs': api_response.result.classifier_config.coef_[0], 'intercept': api_response.result.classifier_config.intercept_[0], 'keywords': api_response.result.keywords}\n",
    "\n",
    "            payload = nucleus_api.DocClassifyModel(dataset=\"OLID_validate\",\n",
    "                                                    fixed_topics=fixed_topics,\n",
    "                                                    classifier_config=classifier_config,\n",
    "                                                    metadata_selection=metadata_selection,\n",
    "                                                    validation_phase=True,\n",
    "                                                    syntax_variables=syntax_variables,\n",
    "                                                    custom_stop_words=custom_stop_words,\n",
    "                                                    remove_redundancies=False)\n",
    "            api_response1 = api_instance.post_doc_classify_api(payload)\n",
    "\n",
    "            if api_response1.result.perf_metrics.f1 > running_best:\n",
    "                optimal_num_keywords = num_keywords\n",
    "                running_best = api_response1.result.perf_metrics.f1\n",
    "        except (AttributeError, IndexError, ZeroDivisionError) as e:\n",
    "                optimal_num_keywords = 0\n",
    "\n",
    "    if optimal_num_keywords > 0:\n",
    "        # then for the compression param that maximized, we test classification performance on a separate sample\n",
    "        try:\n",
    "            payload = nucleus_api.TopicContrastModel(dataset='OLID_train', \n",
    "                                                    metadata_selection=metadata_selection,\n",
    "                                                    num_keywords=optimal_num_keywords,\n",
    "                                                    syntax_variables=syntax_variables,\n",
    "                                                    custom_stop_words=custom_stop_words,\n",
    "                                                    remove_redundancies=False)\n",
    "            api_response = api_instance.post_topic_contrast_api(payload)\n",
    "\n",
    "            fixed_topics = {'weights': api_response.result.keywords_weight, 'keywords': api_response.result.keywords}\n",
    "            classifier_config = {'coefs': api_response.result.classifier_config.coef_[0], 'intercept': api_response.result.classifier_config.intercept_[0], 'keywords': api_response.result.keywords}\n",
    "\n",
    "            payload = nucleus_api.DocClassifyModel(dataset=test_set,\n",
    "                                                    fixed_topics=fixed_topics,\n",
    "                                                    classifier_config=classifier_config,\n",
    "                                                    metadata_selection=metadata_selection,\n",
    "                                                    validation_phase=True,\n",
    "                                                    syntax_variables=syntax_variables,\n",
    "                                                    custom_stop_words=custom_stop_words,\n",
    "                                                    remove_redundancies=False)\n",
    "            api_response1 = api_instance.post_doc_classify_api(payload)\n",
    "            granular_results['Accuracy'].append(api_response1.result.perf_metrics.accuracy)\n",
    "            granular_results['Recall'].append(api_response1.result.perf_metrics.recall)\n",
    "            granular_results['Precision'].append(api_response1.result.perf_metrics.precision) \n",
    "            granular_results['F1'].append(api_response1.result.perf_metrics.f1) \n",
    "        except (AttributeError, IndexError, ZeroDivisionError) as e:\n",
    "            granular_results['Accuracy'].append(np.nan)\n",
    "            granular_results['Recall'].append(np.nan)\n",
    "            granular_results['Precision'].append(np.nan)  \n",
    "            granular_results['F1'].append(np.nan)  \n",
    "    else:\n",
    "        granular_results['Accuracy'].append(np.nan)\n",
    "        granular_results['Recall'].append(np.nan)\n",
    "        granular_results['Precision'].append(np.nan)\n",
    "        granular_results['F1'].append(np.nan)\n",
    "    granular_results['Document_set'].append([my_values[1], my_values[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tFine Tuning\n",
    "\n",
    "#### a.\tReducing noise in your low-quality content detection\n",
    "-\tSee whether some tailoring may be applied to your content classification by excluding certain topics considered not information-bearing for your end-user or your application. This is achieved by using the custom_stop_words parameter in input to the Topic Contrast and Document Classify APIs\n",
    "\n",
    "\n",
    "-\tIdentify and Extract key topics on objectionable documents within your corpus and print the keywords of these topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "metadata_selection = {\"subtask_a\": \"OFF\"}\n",
    "payload = nucleus_api.Topics(dataset=dataset,                         \n",
    "                            query='',                       \n",
    "                            num_topics=20, \n",
    "                            num_keywords=8,\n",
    "                            metadata_selection=metadata_selection)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.post_topic_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    for i, res in enumerate(api_response.result.topics):\n",
    "        print('Topic', i, ' keywords: ', res.keywords)    \n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your domain expertise / client input / advisor input, you can determine whether certain of those topics or keywords are not differentiated enough to contribute to low-quality content detection. \n",
    "\n",
    "You can then tailor the low-quality content detection by creating a custom_stop_words variable that contains those words. Initialize the variable as follows, for instance, and pass it in the payload of the code of section 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"tough dude\",\"bad boy\"] # str | List of stop words. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Focusing the content detection on specific subjects potentially discussed in your corpus\n",
    "**query**: You can refine the content detection by leveraging the query variable of the Contrasted Topic and Document Classify APIs.\n",
    "\n",
    "This can be especially useful when content monitors are flagging objectionable content that typically surrounds specific events not captured by the existing process. One could try to understand ex-post whether such content has characteristic patterns in how users write about it.\n",
    "\n",
    "Create a variable query and pass it in the payload of the code of section 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(christchurch)' # str | Fulltext query, using mysql MATCH boolean query format. Example: \"(word1 OR word2) AND (word3 OR word4)\" (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 SumUp Analytics, Inc. All Rights Reserved.\n",
    "\n",
    "NOTICE: All information contained herein is, and remains the property of SumUp Analytics Inc. and its suppliers, if any. The intellectual and technical concepts contained herein are proprietary to SumUp Analytics Inc. and its suppliers and may be covered by U.S. and Foreign Patents, patents in process, and are protected by trade secret or copyright law.\n",
    "\n",
    "Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from SumUp Analytics Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
