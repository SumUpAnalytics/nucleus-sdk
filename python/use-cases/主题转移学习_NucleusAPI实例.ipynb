{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  主题转移学习 -  Nucleus API实例</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  所有权及保密条款属SumUp Analytics所有</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  免责声明和服务条款可通过 www.sumup.ai 获取</center></h1>\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## 目标: \n",
    "-\t提取参考数据集的主题并测量验证数据集中的关键指标（强度，情绪，共识，暴露）\n",
    "\n",
    "\n",
    "## 数据:\n",
    "-\t任何两个数据集，无论是按时间排序还是通过其他方法选择\n",
    "\n",
    "    **Nucleus Datafeed可直接调用主要中央银行的所有内容**\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\t数据集创建 API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files利用api_instance.post_upload_file并行执行来加速数据集的创建\n",
    "\n",
    "\n",
    "-\t主题建模 API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "-\t主题转移 API\n",
    " - \t*api_instance.post_topic_transfer_api(payload)*\n",
    "\n",
    "\n",
    "-\t主题情感转移 API\n",
    " - \t*api_instance.post_topic_sentiment_transfer_api(payload)*\n",
    "\n",
    "\n",
    "-\t主题共识转移 API\n",
    " - \t*api_instance.post_topic_consensus_transfer_api(payload)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法:\n",
    "\n",
    "### 1.\t数据集准备\n",
    "-\t创建一个Nucleus数据集，其中包含所选历史时期内的所有相关文档\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "\n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-SERVER-HOSTNAME'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'\n",
    "\n",
    "# 创建API实例\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用自己的语库\n",
    "print('---- Case 1: you are using your own corpus, coming from a local folder ----')\n",
    "folder = 'News_feed'         \n",
    "dataset = 'News_feed'# str | Destination dataset where the file will be inserted.\n",
    "\n",
    "# 以递归方式从文件夹构建文件。 \n",
    "# 每一项采用以下格式：\n",
    "# {'filename': filename,   # 要上传的文件名。 需要\n",
    "#  'metadata': {           # 该文件的元数据。 可选\n",
    "#      'key1': val1,       # 只要名称，密钥就可以有任意名称\n",
    "#      'key2': val2        # 包含字母数字（0-9 | a-z | A-Z）和下划线（_）\n",
    "#   } \n",
    "# }\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        #if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "        file_dict = {'filename': os.path.join(root, file),\n",
    "                     'metadata': {'source': 'Tech Crunch',\n",
    "                                  'author': 'Sarah Moore'\n",
    "                                  'category': 'Media',\n",
    "                                  'date': '2019-01-01'}}\n",
    "        file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)\n",
    "\n",
    "    \n",
    "# 利用Nucleus自带Feed\n",
    "print('---- Case 2: you are using an embedded datafeed ----')\n",
    "dataset = 'sumup/rss_feed_finance'# 在Nucleus中调用数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t您可以仅保留在选定的回顾期间发布的文档的子集\n",
    "\n",
    "**这可以直接在执行内容分析的API中完成，如下所示**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\t转移学习\n",
    "-\t提取参考数据集上的关键主题\n",
    "\n",
    "\n",
    "-\t在验证数据集上测量每个主题的强度，情绪和共识\n",
    "\n",
    "\n",
    "-   测量验证数据集中每个文档对每个主题的曝光和情感贡献\n",
    "\n",
    "\n",
    "-\t使用用户可用的不同参数优化转移学习\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- Get topic transfer -----------------------')\n",
    "\n",
    "payload = nucleus_api.TopicTransferModel(dataset0='News_feed', \n",
    "                                         dataset1=\"test_feed\",\n",
    "                                        query='', \n",
    "                                        custom_stop_words='', \n",
    "                                        num_topics=8, \n",
    "                                        num_keywords=8,\n",
    "                                        metadata_selection='')\n",
    "try:\n",
    "    api_response = api_instance.post_topic_transfer_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    doc_ids_t1 = api_response.result.doc_ids_t1\n",
    "    topics = api_response.result.topics\n",
    "    for i,res in enumerate(topics):\n",
    "        print('Topic', i, 'exposure within validation dataset:')\n",
    "        print('    Keywords:', res.keywords)\n",
    "        print('    Strength:', res.strength)\n",
    "        print('    Document IDs:', doc_ids_t1)\n",
    "        print('    Exposure per Doc in Validation Dataset:', res.doc_topic_exposures_t1)\n",
    "        print('---------------')\n",
    "    \n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t对主题情感转移或/和主题共识转移重复上述任务，具体取决于您希望从参考转移到验证的分析的哪个方面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- Get topic sentiment transfer -----------------------')\n",
    "\n",
    "payload = nucleus_api.TopicSentimentTransferModel(dataset0='News_feed', \n",
    "                                        query='', \n",
    "                                        custom_stop_words='', \n",
    "                                        num_topics=8, \n",
    "                                        num_keywords=8,\n",
    "                                        period_0_start='2018-08-12',\n",
    "                                        period_0_end='2018-08-15',\n",
    "                                        period_1_start='2018-08-16',\n",
    "                                        period_1_end='2018-08-19',\n",
    "                                        metadata_selection='')\n",
    "try:\n",
    "    api_response = api_instance.post_topic_sentiment_transfer_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    topics = api_response.result\n",
    "    for i,res in enumerate(topics):\n",
    "        print('Topic', i, 'exposure within validation dataset:')\n",
    "        print('    Keywords:', res.keywords)\n",
    "        print('    Strength:', res.strength)\n",
    "        print('    Sentiment:', res.sentiment)\n",
    "        print('    Document IDs:', res.doc_ids_t1)\n",
    "        print('    Sentiment per Doc in Validation Dataset:', res.doc_sentiments_t1)\n",
    "        print('---------------')\n",
    "    \n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------- Get topic consensus transfer -----------------------')\n",
    "\n",
    "payload = nucleus_api.TopicConsensusTransferModel(dataset0='News_feed', \n",
    "                                        query='', \n",
    "                                        custom_stop_words='', \n",
    "                                        num_topics=8, \n",
    "                                        num_keywords=8,\n",
    "                                        period_0_start='2018-08-12',\n",
    "                                        period_0_end='2018-08-15',\n",
    "                                        period_1_start='2018-08-16',\n",
    "                                        period_1_end='2018-08-19',\n",
    "                                        metadata_selection='')\n",
    "try:\n",
    "    api_response = api_instance.post_topic_consensus_transfer_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    topics = api_response.result\n",
    "    for i,res in enumerate(topics):\n",
    "        print('Topic', i, 'exposure within validation dataset:')\n",
    "        print('    Keywords:', res.keywords)\n",
    "        print('    Consensus:', res.consensus)\n",
    "        print('---------------')\n",
    "    \n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\t结果解释\n",
    "-\t参考和验证数据集上的度量标准之间可能的比较，或使用验证数据集上的度量标准生成生成信号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\t微调\n",
    "\n",
    "#### a.\t量身定制主题\n",
    "\n",
    "-   排除不相关或次要主题，以便通过使用Topic Transfer API中的`custom stop_words`参数来定制您的转移学习\n",
    "\n",
    "\n",
    "-\t提取参考文档中的关键主题并打印其关键字\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset='News_feed',                         \n",
    "                            query='',                       \n",
    "                            num_topics=8, \n",
    "                            num_keywords=8,\n",
    "                            metadata_selection=metadata_selection,\n",
    "                            period_start='2018-08-12',\n",
    "                            period_end='2018-08-15')\n",
    "try:\n",
    "    api_response = api_instance.post_topic_api(payload)        \n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:    \n",
    "    for i, res in enumerate(api_response.result.topics):\n",
    "        print('Topic', i, ' keywords: ', res.keywords)    \n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，您可以通过创建custom_stop_words变量来定制传输学习。 如下所示初始化变量，并将其传递到第2节主代码的有效负载中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"conference\",\"interview\"] # str | 停用词列表。 （可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\t将转移学习集中在某些科目上\n",
    "如果您决定关注转移学习，例如关注政策和宏观经济主题，只需将第2节主要代码中的查询变量替换为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(inflation OR growth OR unemployment OR stability OR regulation)' # str | Fulltext query, using mysql MATCH boolean query format. Example: \"(word1 OR word2) AND (word3 OR word4)\" (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\t验证数据集的替代规范\n",
    "**validation dataset**: 有两种可能的方法。\n",
    "\n",
    "1) 如果参考和验证数据集是按时间排序的，\n",
    " - 将属于验证数据集的文档附加到参考数据集\n",
    " - 使用时间选择器来定义哪个时间段是引用，哪个是验证\n",
    "\n",
    "2) 如果参考和验证数据集不一定是时间排序的，\n",
    " - 将两个不同的数据集传递给Topic Transfer API。\n",
    " - dataset0将是您的参考数据集，dataset1将是验证数据集。\n",
    "\n",
    "请注意，如果从参考数据集中提取的主题不在验证数据集中，则主题传输可能不会导致任何结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. 外部指定主题\n",
    "\n",
    "您可以强制要转移到验证数据集的主题。 要将它们传递给任何Transfer Learning API，请在有效内容中使用`fixed_topics`可选输入参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例1：用英语决定权重\n",
    "fixed_topics = [{\"keywords\":[\"inflation expectations\", \"forward rates\", \"board projections\"], \"weights\":[0.7, 0.2, 0.1]}]\n",
    "\n",
    "# 示例2：英文，您不提供权重。 然后将使用相等的权重\n",
    "fixed_topics = [{\"keywords\":[\"inflation expectations\", \"forward rates\", \"board projections\"]}]\n",
    "\n",
    "# 示例3：中文（如果您的数据集是中文）并且您没有提供权重\n",
    "fixed_topics = [{\"keywords\":[\"操作\", \"流动性\", \"基点\", \"元\", \"点\", \"央行\", \"进一步\", \"投资\"]},\n",
    "                {\"keywords\":[\"认为\", \"价格\", \"数据\", \"调查\", \"全国\", \"统计\", \"金融市场\", \"要求\"]}]\n",
    "\n",
    "\n",
    "payload = nucleus_api.TopicTransferModel(dataset0='News_feed', \n",
    "                                        dataset1=\"test_feed\",\n",
    "                                        fixed_topics=fixed_topics,\n",
    "                                        query='', \n",
    "                                        custom_stop_words='', \n",
    "                                        num_topics=8, \n",
    "                                        num_keywords=8,\n",
    "                                        metadata_selection='')\n",
    "try:\n",
    "    api_response = api_instance.post_topic_transfer_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    doc_ids_t1 = api_response.result.doc_ids_t1\n",
    "    topics = api_response.result.topics\n",
    "    for i,res in enumerate(topics):\n",
    "        print('Topic', i, 'exposure within validation dataset:')\n",
    "        print('    Keywords:', res.keywords)\n",
    "        print('    Strength:', res.strength)\n",
    "        print('    Document IDs:', doc_ids_t1)\n",
    "        print('    Exposure per Doc in Validation Dataset:', res.doc_topic_exposures_t1)\n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "版权(c) 2019年 SumUp Analytics 公司 版权所有。 \n",
    "\n",
    "通知：所有信息均属于SumUp Analytics Inc公司及其供应商的财产。 本合同所包含的知识产权和技术概念属于SumUp Analytics Inc.及其供应商的专利，可由美国和外国专利、在工艺中的专利以及受贸易秘密或版权法保护的专利涵盖。 \n",
    "\n",
    "除非得到SumUp Analytics公司的事先书面批准，否则严禁传播此类信息或复制此材料。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
