{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  股票情绪  -  Nucleus API用例</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  所有权及保密条款属SumUp Analytics所有</center></h1>\n",
    "<h1><center>  免责声明和服务条款可通过 www.sumup.ai 获取</center></h1>\n",
    "\n",
    "\n",
    "#  \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## 目标: \n",
    "-\t使用卖方研究报告衡量特定股票的情绪\n",
    "\n",
    "\n",
    "## 数据:\n",
    "-\t卖方股票研究报告\n",
    "-   SEC备案,比如8K\n",
    "\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\t数据集创建 API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files利用api_instance.post_upload_file并行执行来加速数据集的创建\n",
    "        \n",
    "\n",
    "-\t文件情绪 API\n",
    " - \t*api_instance.post_doc_sentiment_api(payload)*\n",
    "\n",
    "\n",
    "\n",
    "-\t主题建模 API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "\n",
    "-\tDocInfo API\n",
    " - \t*api_instance.post_doc_info(payload)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法:\n",
    "\n",
    "### 1.\t数据集准备\n",
    "-\t创建一个Nucleus数据集，其中包含所选历史时期内的所有相关文档\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "\n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-SERVER-HOSTNAME'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'\n",
    "\n",
    "# 创建API实例\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------- Append all files from local folder to dataset in parallel -----------')\n",
    "folder = 'Sellside_research'         \n",
    "dataset = 'Sellside_research'# str | 文件的目标数据集。\n",
    "\n",
    "# 以递归方式从文件夹构建文件。 \n",
    "# 每一项采用以下格式：\n",
    "# {'filename': filename,   # 要上传的文件名。 需要\n",
    "#  'metadata': {           # 该文件的元数据。 可选\n",
    "#      'key1': val1,       # 只要名称，密钥就可以有任意名称\n",
    "#      'key2': val2        # 包含字母数字（0-9 | a-z | A-Z）和下划线（_）\n",
    "#   } \n",
    "# }\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        #if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "            file_dict = {'filename': os.path.join(root, file),\n",
    "                         'metadata': {'ticker': 'AAPL',\n",
    "                                      'company': 'Apple',\n",
    "                                      'bank': 'Credit Suisse',\n",
    "                                      'category': 'sell side research'\n",
    "                                      'date': '2019-01-01'}}\n",
    "            file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t使用SEC文件和嵌入式Nucleus数据传输的替代方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Corporate_docs\" \n",
    "period_start = \"2010-01-01\" \n",
    "period_end= \"2019-06-01\"\n",
    "\n",
    "payload = nucleus_api.EdgarQuery(destination_dataset=dataset,\n",
    "                                tickers=[\"FB\", \"AMZN\", \"INTL\", \"IBM\", \"NFLX\", \"GOOG\"], \n",
    "                                filing_types=[\"8-K\", \"8-K/A\"], \n",
    "                                sections=[],\n",
    "                                period_start=period_start,\n",
    "                                period_end=period_end)\n",
    "\n",
    "api_response = api_instance.post_create_dataset_from_sec_filings(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**您可以随后直接在API中处理数据集中的特定时间段，如下所示**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\t衡量一只股票的情绪\n",
    "- 选择与库存相关的所有文档\n",
    "\n",
    "\n",
    "- 衡量每个讨论公司的文件的情绪\n",
    "\n",
    "\n",
    "- 将报告的情绪汇总到公司的情绪中\n",
    " \n",
    " \n",
    "- 接下来，我们将讨论如何利用用户可用的不同参数来优化此分析\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取与所选公司相关的所有文档\n",
    "import numpy as np\n",
    "\n",
    "payload = nucleus_api.DocInfo(dataset='Sellside_research',\n",
    "                             metadata_selection={'ticker': 'AAPL'})\n",
    "api_response = api_instance.post_doc_info(payload)\n",
    "\n",
    "doc_list = []\n",
    "for res in api_response.result:        \n",
    "    doc_list.append(res.title) \n",
    "\n",
    "doc_list = np.unique(doc_list)\n",
    "\n",
    "print('-------- Get the sentiment of each document ----------------')\n",
    "reports_sentiment = []\n",
    "for i in range(len(company_list)):\n",
    "    payload = nucleus_api.DocumentSentimentModel(dataset='Sellside_research', \n",
    "                                                doc_title=doc_list[i], \n",
    "                                                custom_stop_words=\"\", \n",
    "                                                num_topics=10, \n",
    "                                                num_keywords=10)\n",
    "    try:\n",
    "        api_response = api_instance.post_doc_sentiment_api(payload)\n",
    "        api_ok = True\n",
    "    except ApiException as e:\n",
    "        api_error = json.loads(e.body)\n",
    "        print('ERROR:', api_error['message'])\n",
    "        api_ok = False\n",
    "\n",
    "    if api_ok:    \n",
    "        reports_sentiment.append(api_response.result.sentiment)\n",
    "\n",
    "# 将每份报告中的情绪加入公司的情绪中\n",
    "company_sentiment = np.mean(reports_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tRepeat the above tasks for each company you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 您感兴趣的公司名单\n",
    "company_list = ['AAPL', 'GOOG', 'FB', 'BABA', 'NFLX']\n",
    "\n",
    "# 仔细检查每一个并获得情绪\n",
    "company_sentiment = []\n",
    "for i in range(len(company_list)):  \n",
    "    # 获取讨论给定公司的所有文档\n",
    "    payload = nucleus_api.DocInfo(dataset='Sellside_research',\n",
    "                                 metadata_selection={'ticker': company_list[i]})\n",
    "    try:\n",
    "        api_response = api_instance.post_doc_info(payload)\n",
    "        api0_ok = True\n",
    "    except ApiException as e:\n",
    "        api_error = json.loads(e.body)\n",
    "        print('ERROR:', api_error['message'])\n",
    "        api0_ok = False\n",
    "\n",
    "    if api0_ok:\n",
    "        doc_list = []\n",
    "        for res in api_response.result:        \n",
    "            doc_list.append(res.title) \n",
    "\n",
    "        doc_list = np.unique(doc_list)\n",
    "\n",
    "        # 获取每个文档的情绪\n",
    "        reports_sentiment = []\n",
    "        for j in range(len(company_list)):\n",
    "            payload = nucleus_api.DocumentSentimentModel(dataset='Sellside_research', \n",
    "                                                        doc_title=doc_list[j], \n",
    "                                                        custom_stop_words=\"\", \n",
    "                                                        num_topics=10, \n",
    "                                                        num_keywords=10)\n",
    "            try:\n",
    "                api_response = api_instance.post_doc_sentiment_api(payload)\n",
    "                api_ok = True\n",
    "            except ApiException as e:\n",
    "                api_error = json.loads(e.body)\n",
    "                print('ERROR:', api_error['message'])\n",
    "                api_ok = False\n",
    "\n",
    "            if api_ok:\n",
    "                reports_sentiment.append(api_response.result.sentiment)\n",
    "\n",
    "    # 将每份报告中的情绪加入公司的情绪中\n",
    "    company_sentiment.append(np.mean(reports_sentiment, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\t结果解释\n",
    "-\t在一个行业部门中绘制公司情绪的时间序列; 或针对每家公司的股票回报序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\t微调\n",
    "\n",
    "#### a.\t量身定制主题\n",
    "-   通过使用Contrast Analysis API中的`custom_stop_words`参数，排除无关紧要或次要主题，以定制您公司的情绪\n",
    "\n",
    "\n",
    "-\t在文档子集中提取对比主题的关键字并打印这些主题的关键字\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset='Sellside_research',                       \n",
    "                            query='',                       \n",
    "                            num_topics=20, \n",
    "                            num_keywords=5,\n",
    "                            metadata_selection={'ticker': 'AAPL'})\n",
    "try:\n",
    "    api_response = api_instance.post_topic_api(payload)        \n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:    \n",
    "    for i, res in enumerate(api_response.result.topics):\n",
    "        print('Topic', i, ' keywords: ', res.keywords)    \n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，您可以通过创建custom_stop_words变量来定制公司的情绪。 如下所示，将初始化变量传递到第2节主代码的有效负载中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"call\",\"report\"] # str | 停用词列表。 （可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\t探索文档类型，回顾期，提取的主题数量的影响\n",
    "\n",
    "**num_topics**: 您可以通过更改第2部分主要代码中有效负载中的变量`num_topics`来使用不同广度的主题来计算公司的情绪。\n",
    "- 在建立情绪时，较大的值将包含更广泛的主题/内容，而较小的值将提供具有主要主题的浓缩度量。\n",
    "- 如果`num_topics`太大，一些非常边缘的话题可能会在衡量公司情绪方面带来很多噪音。\n",
    "\n",
    "\n",
    "**Document types**: 您可以使用卖方研究，新闻或公司出版物来调查公司的情绪如何变化。 在那些不同的数据集上重新运行第2节的主要代码。 您还可以构建包含跨提供程序的所有内容的数据集，然后使用`metadata_selection`仅选择某些类型的文档："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"category\": \"News\"}   # str | json object of {\\\"metadata_field\\\":[\\\"selected_values\\\"]} (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\t下一步\n",
    "-\t可能的扩展：针对不同的行业部门重复上述任务\n",
    " - 汇总某个行业中每家公司的情绪，以获得行业情绪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "版权(c) 2019年 SumUp Analytics 公司 版权所有。\n",
    "\n",
    "通知：所有信息均属于SumUp Analytics Inc公司及其供应商的财产。 本合同所包含的知识产权和技术概念属于SumUp Analytics Inc.及其供应商的专利，可由美国和外国专利、在工艺中的专利以及受贸易秘密或版权法保护的专利涵盖。\n",
    "\n",
    "除非得到SumUp Analytics公司的事先书面批准，否则严禁传播此类信息或复制此材料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
