{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  低质量内容检测 -  Nucleus API实例</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  所有权及保密条款属SumUp Analytics所有</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  免责声明和服务条款可通过 www.sumup.ai 获取 </center></h1>\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## 目标: \n",
    "-\t开发一条管道以检测社交媒体或游戏聊天室中的低质量内容\n",
    "\n",
    "**在其当前版本中，SumUp对比度分析将两个类别相互比较，其中用户定义两个类别。**\n",
    "\n",
    "## 数据:\n",
    "-\t来自社交媒体或游戏平台的标签语库\n",
    " -     您的语库中可以有多个标签，但在学习/预测时算法将是二进制分类\n",
    " \n",
    " \n",
    " - 用于低质量内容检测的说明性标签: \n",
    "  - \"Violence\" （暴力）\n",
    "  - \"Drugs\"（毒品）\n",
    "  - \"Pornographic\" （色情）\n",
    "  - \"Religiously Sensitive\" （宗教敏感）\n",
    "  - \"Politically Sensitive\" （政治敏感）\n",
    "  - \"Scam\"（诈骗）\n",
    "  - \"Clickbait\"\n",
    "  - \"Fake\" （假）\n",
    "  - \"All clear\"（全部清除）\n",
    "\n",
    "\n",
    "\n",
    "## Nucleus APIs:\n",
    "-\t数据集创建  API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files利用api_instance.post_upload_file并行执行来加速数据集的创建\n",
    "\n",
    "\n",
    "-\t主题建模 API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "-\t对比主题建模 API\n",
    " - \t*api_instance.post_topic_contrast_api(payload)*\n",
    "\n",
    "\n",
    "-\t文件分类 API\n",
    " - \t*api_instance.post_doc_classify_api(payload)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法:\n",
    "\n",
    "### 1.\t数据集准备\n",
    "-\t创建一个Nucleus数据集，其中包含所选历史时期内的所有相关文档\n",
    "\n",
    "\n",
    "-   在这种情况下，我们使用存储为csv文件的数据。 可以构建类似的代码以从数据库表中注入。 对传递给API以创建数据集的数据和元数据字段的名称有一些要求\n",
    "\n",
    "\n",
    "    - 上传数据的模板: [\"author\", \"label\", \"time\", \"content\", \"title\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "\n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-SERVER-HOSTNAME'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'\n",
    "\n",
    "# 创建API实例\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'social-media.csv'\n",
    "dataset = 'social-media'# str | Destination dataset where the file will be inserted.\n",
    "\n",
    "with open(csv_file, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    json_props = nucleus_helper.upload_jsons(api_instance, dataset, reader, processes=4)\n",
    "    \n",
    "    total_size = 0\n",
    "    total_jsons = 0\n",
    "    for jp in json_props:\n",
    "        total_size += jp.size\n",
    "        total_jsons += 1\n",
    "        \n",
    "    print(total_jsons, 'JSON records (', total_size, 'bytes) appended to', dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 对比主题建模\n",
    "\n",
    "-     在这个例子中，我们定义和对比两个类别，即“Violence”(暴力)和“All clear”（清除）。\n",
    "\n",
    "\n",
    "-     我们提取分隔这两个类别的对比主题（及其关键字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection_contrast = {\"label\": [\"Violence\", \"All clear\"]} # dict | 元数据选择定义了两类文档，以便相互对比和总结\n",
    "query = '' # str | Dataset-language-specific全文查询，使用mysql MATCH boolean query格式（可选）\n",
    "custom_stop_words = [\"\"] # 停用词列表。 （可选）\n",
    "excluded_docs = '' # str | 应从分析中排除的文档ID列表。 例如，[“docid1”，“docid2”，...，“docidN”]（可选）\n",
    "syntax_variables = False # bool | 指定是否考虑每类文档的语法方面以帮助对比它们（可选）（默认为False）\n",
    "num_keywords = 200 # integer | 从数据集中提取的比较主题的关键字数。 (可选) (默认为50)\n",
    "remove_redundancies = False # bool | 如果为True，则此选项从分析中删除准重复项，并仅重新获取其副本。 准复制将具有相同的NLP表示，但不一定是完全相同的文本。 （可选）（默认为False）\n",
    "\n",
    "payload = nucleus_api.TopicContrastModel(dataset=dataset, \n",
    "                                         metadata_selection_contrast=metadata_selection_contrast,\n",
    "                                         num_keywords=num_keywords,\n",
    "                                         syntax_variables=syntax_variables,\n",
    "                                         period_start='2018-01-01',\n",
    "                                         period_end='2018-01-01')\n",
    "try:\n",
    "    api_response = api_instance.post_topic_contrast_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    topic_contrast_result = api_response.result\n",
    "    print('Contrasted Topic')\n",
    "    print('    Keywords:', topic_contrast_result.keywords)\n",
    "    print('    Keywords Weight:', topic_contrast_result.keywords_weight)\n",
    "\n",
    "    print('In-Sample Perf Metrics')\n",
    "    print('    Accuracy:', topic_contrast_result.perf_metrics.hit_rate)\n",
    "    print('    Recall:', topic_contrast_result.perf_metrics.recall)\n",
    "    print('    Precision:', topic_contrast_result.perf_metrics.precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.文件分类\n",
    "\n",
    "此任务需要3个步骤:\n",
    "1. 使用TopicContrastModel（之前已完成），在带标签的数据集上准备对比主题。\n",
    "\n",
    "\n",
    "2. 通过提供标记数据集来训练分类器。 \n",
    " - 从对比主题调整每个关键字的权重\n",
    " - 删除某些关键字\n",
    " - 将步骤1生成的对比主题与您自己选择的主题进行比较\n",
    "\n",
    "\n",
    "3. 测试分类器\n",
    "\n",
    "\n",
    "在下面的示例中，我们假设已经获得了对比主题（步骤1）。 'fixed_topics'的结构正是Contrasted Topic API的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这里，我们重新使用第2节中的对比主题\n",
    "fixed_topics = {\"keywords\": topic_contrast_result.keywords, \n",
    "                \"weights\": topic_contrast_result.keywords_weight} # dict | 对比主题用于分隔两类文件。 重量可选\n",
    "\n",
    "metadata_selection_contrast = {\"label\": [\"Violence\", \"All clear\"]} # dict | 一个文档可以通过元数据分类成两类文件\n",
    "\n",
    "query = '' # str | Dataset-language-specific 全文查询，使用mysql MATCH boolean query格式（可选）\n",
    "custom_stop_words = [\"\"] # 停用词列表。 （可选）\n",
    "excluded_docs = '' # str | 应从分析中排除的文档ID列表。 例如，[“docid1”，“docid2”，...，“docidN”]（可选）\n",
    "syntax_variables = False # bool | 如果为True，则分类器将在内容变量之上包含与语法相关的变量（可选）（默认为False）\n",
    "threshold = 0 # float | Threshold value for a document exposure to the contrasted topic, above which the document is assigned to class 1 specified through metadata_selection. (optional) (default to 0)\n",
    "remove_redundancies = False # bool | 如果为True，则此选项从分析中删除准重复项，并仅重新获取其副本。 准复制将具有相同的NLP表示，但不一定是完全相同的文本。 （可选）（默认为False）\n",
    "\n",
    "\n",
    "payload = nucleus_api.DocClassifyModel(dataset=dataset,\n",
    "                                        fixed_topics=fixed_topics,\n",
    "                                        metadata_selection_contrast=metadata_selection_contrast,\n",
    "                                        validation_phase=True,\n",
    "                                        syntax_variables = syntax_variables,\n",
    "                                        period_start='2019-01-01',\n",
    "                                        period_end='2019-01-01')\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.post_doc_classify_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    print('Detailed Results')\n",
    "    print('    Docids:', api_response.result.detailed_results.docids)\n",
    "    print('    Exposure:', api_response.result.detailed_results.exposures)\n",
    "    print('    Estimated Category:', api_response.result.detailed_results.estimated_class)\n",
    "    print('    Actual Category:', api_response.result.detailed_results.true_class)\n",
    "    print('\\n')\n",
    "\n",
    "    print('Out-Sample Perf Metrics')\n",
    "    print('    Accuracy:', api_response.result.perf_metrics.hit_rate)\n",
    "    print('    Recall:', api_response.result.perf_metrics.recall)\n",
    "    print('    Precision:', api_response.result.perf_metrics.precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们可以进入测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = nucleus_api.DocClassifyModel(dataset=dataset,\n",
    "                                        fixed_topics=fixed_topics,\n",
    "                                        metadata_selection_contrast=metadata_selection_contrast,\n",
    "                                        custom_stop_words=custom_stop_words,\n",
    "                                        validation_phase=False,\n",
    "                                        period_start='2019-01-01',\n",
    "                                        period_end='2019-01-01')\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.post_doc_classify_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    print('Detailed Results')\n",
    "    print('    Docids:', api_response.result.detailed_results.docids)\n",
    "    print('    Exposure:', api_response.result.detailed_results.exposures)\n",
    "    print('    Estimated Category:', api_response.result.detailed_results.estimated_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\t微调\n",
    "\n",
    "#### a. 对比主题指定的`metadata_selection_contrast`\n",
    "\n",
    "-     对比包含不同关键字的文档\n",
    "\n",
    "    这对于检测在特定上下文中频繁出现的某些表达式非常有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection_contrast = {\"content\": \"kill hate torture\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-     对比来自不同作者的文件\n",
    "\n",
    "    这对于检测链接到同一实际人员的多个帐户非常有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection_contrast = {\"author\": \"@suspicious_author\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\t降低低质量内容检测中的噪音\n",
    "\n",
    "-   通过使用Contrast Analysis API中的`custom_stop_words`参数，排除无关或次要关键字/主题以定制内容分类\n",
    "\n",
    "\n",
    "-\t提取语料库中文档的关键主题并打印这些主题的关键字\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset=dataset,                         \n",
    "                            query='',                       \n",
    "                            num_topics=20, \n",
    "                            num_keywords=8,\n",
    "                            metadata_selection=metadata_selection_contrast)\n",
    "\n",
    "try:\n",
    "    api_response = api_instance.post_topic_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    for i, res in enumerate(api_response.result.topics):\n",
    "        print('Topic', i, ' keywords: ', res.keywords)    \n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用您的专业知识，您可以确定特定主题或关键字是否没有足够的差异，从而导致低质量的内容检测。\n",
    "\n",
    "\n",
    "然后，您可以通过创建包含这些单词的`custom_stop_words`变量来定制低质量内容检测。 如下所示，将初始化变量传递到第2节主代码的有效负载中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"tough dude\",\"bad boy\"] # str | List of stop words. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. 将内容检测重点放在您的语料库中可能讨论的特定主题上\n",
    "**query**: 您可以通过利用Contrasted Topic和Document Classify API的`query`变量来优化内容检测。\n",
    "\n",
    "从您的语库中提及特定主题的内容中重新运行这两个API中的任何一个。 创建变量查询并将其传递给有效负载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(LOL OR league of legends OR WOW OR world of warcraft)' # str | Fulltext query, using mysql MATCH boolean query format. Example: \"(word1 OR word2) AND (word3 OR word4)\" (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "版权(c) 2019年 SumUp Analytics 公司 版权所有。 \n",
    "\n",
    "通知：所有信息均属于SumUp Analytics Inc公司及其供应商的财产。 本合同所包含的知识产权和技术概念属于SumUp Analytics Inc.及其供应商的专利，可由美国和外国专利、在工艺中的专利以及受贸易秘密或版权法保护的专利涵盖。 \n",
    "\n",
    "除非得到SumUp Analytics公司的事先书面批准，否则严禁传播此类信息或复制此材料。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
