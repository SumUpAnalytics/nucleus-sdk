{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  Contrast Analysis - Nucleus APIs Use Cases</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  SumUp Analytics, Proprietary & Confidential</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  Disclaimers and Terms of Service available at www.sumup.ai</center></h1>\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## Objective: \n",
    "-\tDevelop a pipeline to customize and fine tune contrast analysis of datasets\n",
    "  - Extraction of a contrasted topic\n",
    "  - Contrasted Summarization\n",
    "  - Classification of documents into 2 predefined categories\n",
    "\n",
    "**In its current version, SumUp contrast analysis works on the premise of two distinct categories of documents within a corpus, whichever way those two categories are defined ex-ante by the user based on metadata or content**\n",
    "\n",
    "## Data:\n",
    "-\tAny collection of documents, ideally from the same field, possibly with further refinement in terms of categorization such as document type\n",
    "\n",
    "    **The Nucleus Datafeed can be leveraged for all content from major Central Banks and SEC filings**\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\tDataset creation API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files leverages api_instance.post_upload_file with parallel execution to speed-up the dataset creation\n",
    "\n",
    "\n",
    "-\tTopic Modeling API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "-\tContrasted Topic Modeling API\n",
    " - \t*api_instance.post_topic_contrast_api(payload)*\n",
    " \n",
    " \n",
    "-\tDocument Contrasted Summary API\n",
    " - \t*api_instance.post_document_contrast_summary_api(payload)*\n",
    "\n",
    "\n",
    "-\tDocuments Classification API\n",
    " - \t*api_instance.post_doc_classify_api(payload)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach:\n",
    "\n",
    "### 1.\tDataset Preparation\n",
    "-\tCreate a Nucleus dataset containing all relevant documents\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Case 1: you are using your own corpus, coming from a local folder ----')\n",
    "folder = 'Sellside_research'         \n",
    "dataset = 'Sellside_research'# str | Destination dataset where the file will be inserted.\n",
    "\n",
    "# build file iterable from a folder recursively. \n",
    "# Each item in the iterable is in the format below:\n",
    "# {'filename': filename,   # filename to be uploaded. REQUIRED\n",
    "#  'metadata': {           # metadata for the file. Optional\n",
    "#      'key1': val1,       # keys can have arbiturary names as long as the names only\n",
    "#      'key2': val2        # contain alphanumeric (0-9|a-z|A-Z) and underscore (_)\n",
    "#   } \n",
    "# }\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "            file_dict = {'filename': os.path.join(root, file),\n",
    "                         'metadata': {'company': 'Apple',\n",
    "                                      'research_analyst': 'MS',\n",
    "                                      'date': '2019-01-01'}}\n",
    "            file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)\n",
    "\n",
    "    \n",
    "    \n",
    "print('---- Case 2: you are using an embedded datafeed ----')\n",
    "dataset = 'sumup/central_banks_chinese'# embedded datafeeds in Nucleus.\n",
    "metadata_selection = {'bank': 'people_bank_of_china', 'document_category': ('speech', 'press release')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Contrasted Topic Modeling\n",
    "\n",
    "-     In this example, we define one category of documents as being produced by research analysts at Morgan Stanley. The second category of documents will be comprised of all other research reports.\n",
    "-     We extract one topic that separates those two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"research_analyst\": \"MS\"} # dict | The metadata selection defining the two categories of documents to contrast and summarize against each other\n",
    "\n",
    "query = '' # str | Dataset-language-specific fulltext query, using mysql MATCH boolean query format (optional)\n",
    "custom_stop_words = [\"morgan stanley\"] # List of stop words. (optional)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, [\"docid1\", \"docid2\", ..., \"docidN\"]  (optional)\n",
    "syntax_variables = False # bool | Specifies whether to take into account syntax aspects of each category of documents to help with contrasting them (optional) (default to False)\n",
    "compression = 0.002 # float | Parameter controlling the breadth of the contrasted topic. Contained between 0 and 1, the smaller it is, the more contrasting terms will be captured, with decreasing weight. (optional) (default to 0.000002)\n",
    "remove_redundancies = True # bool | If True, this option removes quasi-duplicates from the analysis. A quasi-duplicate would have the same NLP representation, but not necessarily the exact same text. (optional) (default True)\n",
    "\n",
    "\n",
    "payload = nucleus_api.TopicContrastModel(dataset='Sellside_research', \n",
    "                                        metadata_selection=metadata_selection,\n",
    "                                        custom_stop_words=custom_stop_words,\n",
    "                                        period_start='2018-01-01',\n",
    "                                        period_end='2019-01-01')\n",
    "api_response = api_instance.post_topic_contrast_api(payload)\n",
    "\n",
    "print('Contrasted Topic')\n",
    "print('    Keywords:', api_response.result.keywords)\n",
    "print('    Keywords Weight:', api_response.result.keywords_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tDocument Contrasted Summarization\n",
    "\n",
    "-     In this example, we define one category of documents as being produced by research analysts at Morgan Stanley. The second category of documents will be comprised of all other research reports.\n",
    "\n",
    "\n",
    "-     We summarize what separates those two categories\n",
    "\n",
    "\n",
    "-\tSeveral input parameters to document contrasted summarization are controlling the size of the summary and the contribution of sentences considered too short or too long\n",
    "\n",
    "\n",
    "-\tThe list of custom stopwords, the inclusion of syntax variables, the compression parameter and the removal of redundancies are al affecting the focus and content of the contrasted summary\n",
    "\n",
    "\n",
    "-\tFurther down, we discuss how to construct a customized stopwords list to refine document contrasted summaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------- Get doc contrasted summaries ------------------------')\n",
    "metadata_selection = {\"research_analyst\": \"MS\"} # dict | The metadata selection defining the two categories of documents to contrast and summarize against each other\n",
    "\n",
    "query = '' # str | Dataset-language-specific fulltext query, using mysql MATCH boolean query format (optional)\n",
    "custom_stop_words = [\"morgan stanley\"] # List of stop words. (optional)\n",
    "summary_length = 6 # int | The maximum number of bullet points a user wants to see in the contrasted summary. (optional) (default to 6)\n",
    "context_amount = 0 # int | The number of sentences surrounding key summary sentences in the documents that they come from. (optional) (default to 0)\n",
    "short_sentence_length = 0 # int | The sentence length below which a sentence is excluded from summarization (optional) (default to 4)\n",
    "long_sentence_length = 40 # int | The sentence length beyond which a sentence is excluded from summarization (optional) (default to 40)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, [\"docid1\", \"docid2\", ..., \"docidN\"]  (optional)\n",
    "syntax_variables = True # bool | Specifies whether to take into account syntax aspects of each category of documents to help with contrasting them (optional) (default to False)\n",
    "compression = 0.002 # float | Parameter controlling the breadth of the contrasted summary. Contained between 0 and 1, the smaller it is, the more contrasting terms will be captured, with decreasing weight. (optional) (default to 0.000002)\n",
    "remove_redundancies = True # bool | If True, this option removes quasi-duplicates from the analysis. A quasi-duplicate would have the same NLP representation, but not necessarily the exact same text. (optional) (default True)\n",
    "\n",
    "\n",
    "payload = nucleus_api.DocumentContrastSummaryModel(dataset=\"Sellside_research\", \n",
    "                                                    metadata_selection=metadata_selection,\n",
    "                                                    custom_stop_words=custom_stop_words,\n",
    "                                                    period_start='2018-01-01',\n",
    "                                                    period_end='2019-01-01')\n",
    "api_response = api_instance.post_document_contrast_summary_api(payload)\n",
    "\n",
    "print('Summary for', [x for x in  metadata_selection.values()])\n",
    "for sent in api_response.result.class_1_content.sentences:\n",
    "    print('    *', sent)\n",
    "print('======')\n",
    "for sent in api_response.result.class_2_content.sentences:\n",
    "    print('    *', sent)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Documents Classification\n",
    "\n",
    "This task requires 3 steps:\n",
    "-     First, extract a contrasted topic on a labeled dataset\n",
    "-     Second, train the documents' classifier by providing a labeled dataset. In this step, you can adjust the weight of each keyword from the contrasted topic, remove certain keywords, and even compare the contrasted topic produced by step 1 against topics of your own choosing\n",
    "-     Third, test the classifier\n",
    "\n",
    "-     In the example below, we assume that the contrasted topic has already been obtained. The structure of 'fixed_topics' is exactly that which would come out of the Contrasted Topic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_topics = {\"keywords\": [\"price target\", \"projected revenue\", \"economy\"], \"weights\": [0.5, 0.25, 0.25]} # dict | The contrasting topic used to separate the two categories of documents. Weights optional\n",
    "metadata_selection = {\"research_analyst\": \"MS\"} # dict | The metadata selection defining the two categories of documents that a document can be classified into\n",
    "\n",
    "query = '' # str | Dataset-language-specific fulltext query, using mysql MATCH boolean query format (optional)\n",
    "custom_stop_words = [\"morgan stanley\"] # List of stop words. (optional)\n",
    "excluded_docs = '' # str | List of document IDs that should be excluded from the analysis. Example, [\"docid1\", \"docid2\", ..., \"docidN\"]  (optional)\n",
    "syntax_variables = True # bool | If True, the classifier will include syntax-related variables on top of content variables (optional) (default to False)\n",
    "threshold = 0 # float | Threshold value for a document exposure to the contrastic topic, above which the document is assigned to class 1 specified through metadata_selection. (optional) (default to 0)\n",
    "remove_redundancies = True # bool | If True, this option removes quasi-duplicates from the analysis. A quasi-duplicate would have the same NLP representation, but not necessarily the exact same text. (optional) (default True)\n",
    "\n",
    "\n",
    "payload = nucleus_api.DocClassifyModel(dataset=\"Sellside_research\",\n",
    "                                        fixed_topics=fixed_topics,\n",
    "                                        metadata_selection=metadata_selection,\n",
    "                                        custom_stop_words=custom_stop_words,\n",
    "                                        validation_phase=True,\n",
    "                                        period_start='2018-01-01',\n",
    "                                        period_end='2019-01-01')\n",
    "api_response = api_instance.post_doc_classify_api(payload)\n",
    "\n",
    "print('Detailed Results')\n",
    "print('    Docids:', api_response.result.detailed_results.docids)\n",
    "print('    Exposure:', api_response.result.detailed_results.exposures)\n",
    "print('    Estimated Category:', api_response.result.detailed_results.estimated_class)\n",
    "print('    Actual Category:', api_response.result.detailed_results.true_class)\n",
    "print('\\n')\n",
    "\n",
    "print('Perf Metrics')\n",
    "print('    Accuracy:', api_response.result.perf_metrics.hit_rate)\n",
    "print('    Recall:', api_response.result.perf_metrics.recall)\n",
    "print('    Precision:', api_response.result.perf_metrics.precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can move to the testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_topics = {\"keywords\": [\"price target\", \"projected revenue\", \"economy\"], \"weights\": [0.5, 0.25, 0.25]} # dict | The contrasting topic used to separate the two categories of documents\n",
    "metadata_selection = {\"research_analyst\": \"MS\"} # dict | The metadata selection defining the two categories of documents that a document can be classified into\n",
    "\n",
    "payload = nucleus_api.DocClassifyModel(dataset=\"Sellside_research\",\n",
    "                                        fixed_topics=fixed_topics,\n",
    "                                        metadata_selection=metadata_selection,\n",
    "                                        custom_stop_words=custom_stop_words,\n",
    "                                        validation_phase=False,\n",
    "                                        period_start='2019-01-02',\n",
    "                                        period_end='2019-06-01')\n",
    "api_response = api_instance.post_doc_classify_api(payload)\n",
    "\n",
    "print('Detailed Results')\n",
    "print('    Docids:', api_response.result.detailed_results.docids)\n",
    "print('    Exposure:', api_response.result.detailed_results.exposures)\n",
    "print('    Estimated Category:', api_response.result.detailed_results.estimated_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tFine Tuning\n",
    "\n",
    "#### a.\tExcluding certain content from the contrast analysis\n",
    "-\tSee whether some tailoring may be applied to your contrast analysis by excluding certain topics considered not information-bearing for your end-user or your application. This is achieved by using the custom_stop_words parameter in input to any Contrast Analysis API\n",
    "\n",
    "\n",
    "-\tIdentify and Extract key topics on documents within your corpus and print the keywords of these topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset='Sellside_research',                         \n",
    "                            query='',                       \n",
    "                            num_topics=8, \n",
    "                            num_keywords=8,\n",
    "                            metadata_selection=metadata_selection)\n",
    "api_response = api_instance.post_topic_api(payload)        \n",
    "    \n",
    "for i, res in enumerate(api_response.result.topics):\n",
    "    print('Topic', i, ' keywords: ', res.keywords)    \n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your domain expertise / client input / advisor input, you can determine whether certain of those topics or keywords are not differentiated enough to contribute to contrast analysis. \n",
    "\n",
    "You can then tailor the contrast analysis by creating a custom_stop_words variable that contains those words. Initialize the variable as follows, for instance, and pass it in the payload of the main code of section 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"disclaimer\",\"disclosure\"] # str | List of stop words. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Focusing the contrasted summary on specific subjects potentially discussed in your corpus\n",
    "**query**: You can refine the contrast analysis by leveraging the query variable of the Doc Contrasted Summary API.\n",
    "\n",
    "Rerun any of the 3 Contrast Analysis APIs on the content from your corpus that mentions a specific theme. Create a variable query and pass it in to the payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(earnings OR cash flows)' # str | Fulltext query, using mysql MATCH boolean query format. Example: \"(word1 OR word2) AND (word3 OR word4)\" (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Specifying the metadata_selection for your contrasted topic\n",
    "\n",
    "-     Contrasting documents from two different entities\n",
    "\n",
    "    on your own data, e.g. sell-side research: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"research_analyst\": [\"MS\", \"JPM\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    on SumUp data feed, e.g. Central Banks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"bank\": [\"federal_reserve\", \"ECB\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-     Contrasting different documents from a given entity\n",
    "\n",
    "    on SumUp data feed, e.g. Central Banks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"document_category\": [\"speech\", \"press release\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-     Contrasting documents that contain different keywords\n",
    "\n",
    "    on your own data, or on SumUp data feed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"content\": \"fundamentals\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 SumUp Analytics, Inc. All Rights Reserved.\n",
    "\n",
    "NOTICE: All information contained herein is, and remains the property of SumUp Analytics Inc. and its suppliers, if any. The intellectual and technical concepts contained herein are proprietary to SumUp Analytics Inc. and its suppliers and may be covered by U.S. and Foreign Patents, patents in process, and are protected by trade secret or copyright law.\n",
    "\n",
    "Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from SumUp Analytics Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
