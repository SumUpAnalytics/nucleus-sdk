{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  Stocks Sentiment - Nucleus APIs Use Cases</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  SumUp Analytics, Proprietary & Confidential</center></h1>\n",
    "<h1><center>  Disclaimers and Terms of Service available at www.sumup.ai</center></h1>\n",
    "\n",
    "\n",
    "#  \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## Objective: \n",
    "-\tMeasure the sentiment of specific stocks using sell-side research reports\n",
    "\n",
    "\n",
    "## Data:\n",
    "-\tA collection of equity research reports from the sell-side\n",
    "\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\tDataset creation API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files leverages api_instance.post_upload_file with parallel execution to speed-up the dataset creation\n",
    "        \n",
    "\n",
    "-\tDocument Sentiment API\n",
    " - \t*api_instance.post_doc_sentiment_api(payload)*\n",
    "\n",
    "\n",
    "\n",
    "-\tTopic Modeling API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "\n",
    "-\tDocInfo API\n",
    " - \t*api_instance.post_doc_info(payload)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach:\n",
    "\n",
    "### 1.\tDataset Preparation\n",
    "-\tCreate a Nucleus dataset containing all relevant documents\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------- Append all files from local folder to dataset in parallel -----------')\n",
    "folder = 'Sellside_research'         \n",
    "dataset = 'Sellside_research'# str | Destination dataset where the file will be inserted.\n",
    "\n",
    "# build file iterable from a folder recursively. \n",
    "# Each item in the iterable is in the format below:\n",
    "# {'filename': filename,   # filename to be uploaded. REQUIRED\n",
    "#  'metadata': {           # metadata for the file. Optional\n",
    "#      'key1': val1,       # keys can have arbiturary names as long as the names only\n",
    "#      'key2': val2        # contain alphanumeric (0-9|a-z|A-Z) and underscore (_)\n",
    "#   } \n",
    "# }\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        #if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "            file_dict = {'filename': os.path.join(root, file),\n",
    "                         'metadata': {'ticker': 'AAPL',\n",
    "                                      'company': 'Apple',\n",
    "                                      'bank': 'Credit Suisse',\n",
    "                                      'category': 'sell side research'\n",
    "                                      'date': '2019-01-01'}}\n",
    "            file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tFor a given date in that period, retain only a subset of the documents published during a chosen lookback period\n",
    "\n",
    "**This can be done directly into the APIs that perform content analysis, see below**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tMeasuring the Sentiment of one Stock\n",
    "- Select all documents relating to the stock\n",
    "\n",
    "\n",
    "- Measure the sentiment on each document discussing the company\n",
    "\n",
    "\n",
    "- Aggregate the reports' sentiment into a company' sentiment\n",
    " \n",
    " \n",
    "- Further down, we discuss how to refine this analysis by leveraging the different parameters available to the user\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the documents that relate to a chosen company\n",
    "import numpy as np\n",
    "\n",
    "payload = nucleus_api.DocInfo(dataset='Sellside_research',\n",
    "                             metadata_selection={'ticker': 'AAPL'})\n",
    "api_response = api_instance.post_doc_info(payload)\n",
    "\n",
    "doc_list = []\n",
    "for res in api_response.result:        \n",
    "    doc_list.append(res.title) \n",
    "\n",
    "doc_list = np.unique(doc_list)\n",
    "\n",
    "print('-------- Get the sentiment of each document ----------------')\n",
    "reports_sentiment = []\n",
    "for i in range(len(company_list)):\n",
    "    payload = nucleus_api.DocumentSentimentModel(dataset='Sellside_research', \n",
    "                                                doc_title=doc_list[i], \n",
    "                                                custom_stop_words=\"\", \n",
    "                                                num_topics=10, \n",
    "                                                num_keywords=10)\n",
    "    api_response = api_instance.post_doc_sentiment_api(payload)\n",
    "    \n",
    "    reports_sentiment.append(api_response.result.sentiment)\n",
    "\n",
    "# Add up the sentiment from each report into a sentiment for the company\n",
    "company_sentiment = np.mean(reports_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tRepeat the above tasks for each company you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of companies you are interested in\n",
    "company_list = ['AAPL', 'GOOG', 'FB', 'BABA', 'NFLX']\n",
    "\n",
    "# Go through each of them and get the sentiment\n",
    "company_sentiment = []\n",
    "for i in range(len(company_list)):  \n",
    "    # Get all docs discussing a given company\n",
    "    payload = nucleus_api.DocInfo(dataset='Sellside_research',\n",
    "                                 metadata_selection={'ticker': company_list[i]})\n",
    "    api_response = api_instance.post_doc_info(payload)\n",
    "\n",
    "    doc_list = []\n",
    "    for res in api_response.result:        \n",
    "        doc_list.append(res.title) \n",
    "\n",
    "    doc_list = np.unique(doc_list)\n",
    "\n",
    "    # Get the sentiment of each document\n",
    "    reports_sentiment = []\n",
    "    for j in range(len(company_list)):\n",
    "        payload = nucleus_api.DocumentSentimentModel(dataset='Sellside_research', \n",
    "                                                    doc_title=doc_list[j], \n",
    "                                                    custom_stop_words=\"\", \n",
    "                                                    num_topics=10, \n",
    "                                                    num_keywords=10)\n",
    "        api_response = api_instance.post_doc_sentiment_api(payload)\n",
    "\n",
    "        reports_sentiment.append(api_response.result.sentiment)\n",
    "\n",
    "    # Add up the sentiment from each report into a sentiment for the company\n",
    "    company_sentiment.append(np.mean(reports_sentiment, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tResults Interpretation\n",
    "-\tPlot the time series of company sentiments within one industry sector; or for each company against their stock returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tFine Tuning\n",
    "\n",
    "#### a.\tTailoring the topics\n",
    "-\tSee whether some tailoring may be applied to your company's sentiment by excluding certain topics considered not impactful. This is achieved by using the custom_stop_words parameter in input to the Document Sentiment API\n",
    "\n",
    "\n",
    "-\tIdentify and Extract key topics on the subset of documents that discusses the company\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset='Sellside_research',                       \n",
    "                            query='',                       \n",
    "                            num_topics=20, \n",
    "                            num_keywords=5,\n",
    "                            metadata_selection={'ticker': 'AAPL'})\n",
    "api_response = api_instance.post_topic_api(payload)        \n",
    "    \n",
    "for i, res in enumerate(api_response.result.topics):\n",
    "    print('Topic', i, ' keywords: ', res.keywords)    \n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then tailor the company' sentiment by creating a custom_stop_words variable. Initialize the variable as follows, for instance, and pass it in the payload of the main code of section 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"call\",\"report\"] # str | List of stop words. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tExploring the impact of the type of documents, the lookback period, the number of topics being extracted\n",
    "**num_topics**: You can compute the company's sentiment using different breadth of topics by changing the variable num_topics in the payload in the main code of section 2. A larger value will provide more breadth in establishing sentiment while a smaller value will provide a shallower measure. If num_topics is too large, some very marginal topics may bring in a lot of noise in measuring company sentiment.\n",
    "\n",
    "**Document types**: You can investigate how the company's sentiment changes if it is measured using sell-side research vs news vs company publications. Rerun the main code of section 2. on those different datasets. You could also construct a dataset with all the content across providers and then select only certain types of documents using a metadata_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"category\": \"News\"}   # str | json object of {\\\"metadata_field\\\":[\\\"selected_values\\\"]} (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tNext Steps\n",
    "-\tPossible extension: repeat the above tasks for different industry sectors\n",
    " - Aggregate the sentiment of each company in a sector to get a sector sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 SumUp Analytics, Inc. All Rights Reserved.\n",
    "\n",
    "NOTICE: All information contained herein is, and remains the property of SumUp Analytics Inc. and its suppliers, if any. The intellectual and technical concepts contained herein are proprietary to SumUp Analytics Inc. and its suppliers and may be covered by U.S. and Foreign Patents, patents in process, and are protected by trade secret or copyright law.\n",
    "\n",
    "Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from SumUp Analytics Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
