{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  Directional Rate Trading - Nucleus APIs Use Cases</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  SumUp Analytics, Proprietary & Confidential</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  Disclaimers and Terms of Service available at www.sumup.ai</center></h1>\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## Objective: \n",
    "-\tDevelop an indicator of market rally/sell-off using a measure of macro-economic sentiment in Central Bank’ publications\n",
    "\n",
    "\n",
    "## Data:\n",
    "-\tAll documents published by People Bank of China, in Mandarin, excluding formal research\n",
    " - \tSpeeches\n",
    " - \tPress Releases\n",
    " - \tInformal publications\n",
    "\n",
    "    **The Nucleus Datafeed can be leveraged for all content from major Central Banks**\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\tDataset creation API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files leverages api_instance.post_upload_file with parallel execution to speed-up the dataset creation\n",
    "\n",
    "\n",
    "-\tTopic Modeling API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "-\tTopic Sentiment API\n",
    " - \t*api_instance.post_topic_sentiment_api(payload)*\n",
    "\n",
    "\n",
    "-\tDocInfo API\n",
    " - \t*api_instance.post_doc_info(payload)*\n",
    "\n",
    "\n",
    "-\tDatasetInfo API\n",
    " - \t*api_instance.post_dataset_info(payload)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach:\n",
    "\n",
    "### 1.\tDataset Preparation\n",
    "-\tCreate a Nucleus dataset containing all relevant documents over a chosen historical period\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Append all files from local folder to dataset in parallel ----')\n",
    "dataset = 'sumup/central_banks_chinese'# embedded datafeeds in Nucleus.\n",
    "metadata_selection = {'bank': 'people_bank_of_china', 'document_category': ('speech', 'press release', 'publication')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tFor a given date in that period, retain only a subset of the documents published during a chosen lookback period\n",
    "\n",
    "**This can be done directly into the APIs that perform content analysis, see below**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tSentiment Analysis\n",
    "-\tIdentify and Extract key topics at a given point in time on the subset of documents at that date \n",
    "\n",
    "\n",
    "-\tMeasure the sentiment on each topic and aggregate all topic’ sentiments into a PBOC-level sentiment \n",
    "\n",
    "\n",
    "-\tFurther down, we discuss how to refine the sentiment analysis by leveraging the different parameters available to the user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------- Get topic sentiment ------------------------')\n",
    "\n",
    "payload = nucleus_api.TopicSentimentModel(dataset='sumup/central_banks_chinese',           \n",
    "                                query='',                   \n",
    "                                num_topics=8,\n",
    "                                num_keywords=8,\n",
    "                                metadata_selection=metadata_selection,\n",
    "                                period_start=\"2018-11-01 00:00:00\",\n",
    "                                period_end=\"2019-01-01 00:00:00\")\n",
    "api_response = api_instance.post_topic_sentiment_api(payload)\n",
    "    \n",
    "\n",
    "for i, res in enumerate(api_response.result):\n",
    "    print('Topic', i, ' keywords: ', res.keywords)    \n",
    "    print('    Sentiment:', res.sentiment)\n",
    "    print('---------------')\n",
    "\n",
    "\n",
    "# Aggregate all topic’ sentiments\n",
    "import numpy as np\n",
    "PBOC_sent = np.dot(api_response.result.sentiment, api_response.result.strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tRepeat the above tasks for each date in the historical period to get the complete history of your sentiment indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "print('--------------- Retrieve the time range of the dataset -------------')\n",
    "\n",
    "payload = nucleus_api.DatasetInfo(dataset='sumup/central_banks_chinese', query='')\n",
    "api_response = api_instance.post_dataset_info(payload)\n",
    "\n",
    "first_date = datetime.datetime.fromtimestamp(float(api_response.result.time_range[0]))\n",
    "last_date = datetime.datetime.fromtimestamp(float(api_response.result.time_range[1]))\n",
    "delta = last_date – first_date\n",
    "\n",
    "# Now loop through time and at each date, compute the sentiment indicator for PBOC\n",
    "T = 90 # The look-back period in days\n",
    "\n",
    "PBOC_sentiments = []\n",
    "for i in range(delta.days):  \n",
    "    if i == 1:\n",
    "        end_date = first_date + datetime.timedelta(days=T)\n",
    " \n",
    "    # first and last date used for the lookback period of T days\n",
    "    start_date = end_date - datetime.timedelta(days=T)\n",
    "    start_date_str = start_date.strftime(\"%Y-%M-%d 00:00:00\")\n",
    "\n",
    "    # We want a daily indicator\n",
    "    end_date = end_date + datetime.timedelta(days=1) \n",
    "    end_date_str = end_date.strftime(\"%Y-%M-%d 00:00:00\")\n",
    "\n",
    "    payload = nucleus_api.TopicSentimentModel(dataset=\"sumup/central_banks_chinese\",        \n",
    "                                            query='',                   \n",
    "                                            num_topics=8,\n",
    "                                            num_keywords=8,\n",
    "                                            metadata_selection=metadata_selection,\n",
    "                                            period_start= start_date_str,\n",
    "                                            period_end= end_date_str)\n",
    "    api_response = api_instance.post_topic_sentiment_api(payload)\n",
    "\n",
    "    # Aggregate all topic’ sentiments\n",
    "    PBOC_sentiments.append(np.dot(api_response.result.sentiment, api_response.result.strength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\tResults Interpretation\n",
    "-\tPlot the time series of this PBOC sentiment against government yields, credit spread indices, equity indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\tFine Tuning\n",
    "\n",
    "### a.\tTailoring the topics\n",
    "-\tSee whether some tailoring may be applied to your measure of sentiment by excluding certain topics considered not impactful. This is achieved by using the custom_stop_words parameter in input to the Topic Sentiment API\n",
    "\n",
    "\n",
    "-\tIdentify and Extract key topics on the subset of documents and print their keywords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get list of topics from dataset --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset='sumup/central_banks_chinese',                         \n",
    "                            query='',                       \n",
    "                            num_topics=8, \n",
    "                            num_keywords=8,\n",
    "                            metadata_selection=metadata_selection,\n",
    "                            period_start=\"2018-11-01 00:00:00\",\n",
    "                            period_end=\"2019-01-01 00:00:00\")\n",
    "api_response = api_instance.post_topic_api(payload)        \n",
    "    \n",
    "for i, res in enumerate(api_response.result.topics):\n",
    "    print('Topic', i, ' keywords: ', res.keywords)    \n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then tailor the sentiment analysis by creating a custom_stop_words variable. Initialize the variable as follows, for instance, and pass it in the payload of the main code of section 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"conference\",\"government\"] # str | List of stop words. (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\tFocusing the sentiment analysis on certain subjects\n",
    "In case you decide to focus the sentiment analysis, for instance on policy and macro-economic subjects, simply substitute the query variable in the main code of section 2. with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(inflation OR growth OR unemployment OR stability OR regulation)' # str | Fulltext query, using mysql MATCH boolean query format. Example: \"(word1 OR word2) AND (word3 OR word4)\" (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\tExploring the impact of the type of documents, the lookback period, the number of topics being extracted\n",
    "**num_topics**: You can compute the sentiment indicator using different breadth of topics by changing the variable num_topics in the payload in the main code of section 2. A larger value will provide more breadth in establishing a sentiment indicator while a smaller value will provide a shallower measure. If num_topics is too large, some very marginal topics may bring in a lot of noise in measuring sentiment.\n",
    "\n",
    "**T**: You can compute the sentiment indicator with different speeds of propagation by changing the variable T (lookback) in the main code of section 2. A larger value will provide a slowly changing measure of sentiment while a smaller value will lead to a very responsive sentiment measure. If T is too small, too few documents may be used and this may lead to a lot of noise in measuring sentiment. If T is too long, the sentiment indicator won’t reflect quickly enough important new information. \n",
    "\n",
    "**Document types**: You can investigate how the sentiment indicator changes if it is measured using only one type of document among speech, press release, publications compared to capturing the whole content by leveraging the metadata selector provided during the construction of the dataset. Rerun the main code of section 2. on a subset of the whole corpus. Create a variable metadata_selection and pass it in to the payload:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"document_category\": \"speech\"}   # str | json object of {\\\"metadata_field\\\":[\\\"selected_values\\\"]} (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tNext Steps\n",
    "-\tPossible extension: repeat the above tasks for each of (Federal Reserve, European Central Bank, Bank of England, Bank of Canada, Bank of Japan, Royal Bank of Australia, Bundesbank)\n",
    " - This gives you an indicator per country, which can lead to independent per-country signals\n",
    " - You could also rank each country based on that measure of sentiment and this can lead to a security-selection signal\n",
    "\n",
    "\n",
    "-\tPerform a correlation analysis between the time series of the sentiment indicator and either of government yields, credit spread indices, equity indices\n",
    " - Several time horizons for price impact can be studied: 1 day, 7 days, a few weeks, perhaps even longer lasting impact\n",
    " - Several time lags for price impact can be studied: following day, 2 to 3 days gap before market starts adjusting, a week, perhaps even longer gap before markets start incorporating the information from the Central Banks sentiment\n",
    " - Which underlying asset appear to have the strongest response? Within an asset class, are physical securities or Futures responding more?\n",
    "\n",
    "\n",
    "-\tPossible extension: explore simple transformation of the indicator \n",
    " - If you have independent per-country indicators, you could rescale and smooth these indicators using a time-series score \n",
    "\n",
    "            Score(t) = ( Indicator(t) – Average(Indicator, [t – N  ; t]) ) / Std(Indicator, [t – N  ; t])\n",
    "\n",
    " - If you have a ranking of countries based on each sentiment indicator, you could rescale and smooth these rankings using a cross-sectional score\n",
    "\n",
    "            Score(Bank i) = ( Indicator( Bank i) – Average(Indicator, [Banks]) ) / Std(Indicator, [Banks])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regression object\n",
    "\n",
    "# Train the model using the training sets\n",
    "# change in SentimentIndicator is your x\n",
    "# change in rate or any other tradable asset is your y\n",
    "\n",
    "# 1. Predict direction of rates\n",
    "regr.fit(change in SentimentIndicator(t- p), sign(change in rate )(t)) # There may be a lag = p between the indicator and market response. To test.\n",
    "\n",
    "# 2. Predict both direction and size of the move\n",
    "regr.fit(change in SentimentIndicator(t- p), (change in rates)(t))\n",
    "\n",
    "fitted_score = regr.score(change in SentimentIndicator, change in rates)\n",
    "\n",
    "# Forecast stock return for the latest released doc using the exposures of that doc to the topics + the fitting\n",
    "y_predicted = regr.fit(x, y).predict(x.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 SumUp Analytics, Inc. All Rights Reserved.\n",
    "\n",
    "NOTICE: All information contained herein is, and remains the property of SumUp Analytics Inc. and its suppliers, if any. The intellectual and technical concepts contained herein are proprietary to SumUp Analytics Inc. and its suppliers and may be covered by U.S. and Foreign Patents, patents in process, and are protected by trade secret or copyright law.\n",
    "\n",
    "Dissemination of this information or reproduction of this material is strictly forbidden unless prior written permission is obtained from SumUp Analytics Inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
