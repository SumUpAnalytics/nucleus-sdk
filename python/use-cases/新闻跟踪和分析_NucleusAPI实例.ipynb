{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  新闻跟踪和分析 -  Nucleus API实例</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  所有权及保密条款属SumUp Analytics所有</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  免责声明和服务条款可通过 www.sumup.ai 获取 </center></h1> \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## 目标: \n",
    "-\t开发一个工作流程以执行以下操作。\n",
    " - 识别和跟踪新闻/社交媒体中的某些主题\n",
    " - 从主要贡献者和外卖方面分析这些主题\n",
    "\n",
    "\n",
    "## 数据:\n",
    "-\t新闻媒体RSS的集合\n",
    "-   社交媒体供稿\n",
    "\n",
    "    **Nucleus Datafeed自带200个新闻媒体RSS的内容**\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\t数据集创建 API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files利用api_instance.post_upload_file并行执行来加速数据集的创建\n",
    "\n",
    "-\t主题建模 API\n",
    " - \t*api_instance.post_topic_api(payload)*\n",
    "\n",
    "\n",
    "-\t主题历史分析 API\n",
    " - \t*api_instance.post_topic_historical_analysis_api(payload)*\n",
    "\n",
    "\n",
    "-\t作者连接 API\n",
    " - \t*api_instance.post_author_connectivity_api(payload)*\n",
    " \n",
    "\n",
    "-\t主题摘要 API\n",
    " -  *api_instance.post_topic_summary_api(payload)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法:\n",
    "\n",
    "### 1.\t数据集准备\n",
    "-\t创建一个Nucleus数据集，其中包含所选历史时期内的所有相关文档\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "\n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-SERVER-HOSTNAME'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'\n",
    "\n",
    "# 创建API实例\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用自己的语料库\n",
    "print('---- Case 1: you are using your own corpus, coming from a local folder ----')\n",
    "folder = 'Twitter_feed'         \n",
    "dataset = 'Twitter_feed'# str | 文件的目标数据集。\n",
    "\n",
    "# 以递归方式从文件夹构建文件。 \n",
    "# 其中每一项采用以下格式：\n",
    "# {'filename': filename,   # 要上传的文件名。 需要\n",
    "#  'metadata': {           # 该文件的元数据。 可选\n",
    "#      'key1': val1,       # 只要名称，密钥就可以有任意名称\n",
    "#      'key2': val2        # 包含字母数字（0-9 | a-z | A-Z）和下划线（_）\n",
    "#   } \n",
    "# }\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        #if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "        file_dict = {'filename': os.path.join(root, file),\n",
    "                     'metadata': {'source': 'Tech Crunch',\n",
    "                                  'author': 'Sarah Moore'\n",
    "                                  'category': 'Media',\n",
    "                                  'date': '2019-01-01'}}\n",
    "        file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)\n",
    "\n",
    "    \n",
    "# 利用Nucleus自带Feed \n",
    "print('---- Case 2: you are using an embedded datafeed ----')\n",
    "dataset = 'sumup/rss_feed_ai'# 在Nucleus中导入自带数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t对于该期间的给定日期，仅保留在所选回顾期间发布的文档的子集\n",
    "\n",
    "**这可以直接在执行内容分析的API中完成，如下所示**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\t内容分析和跟踪\n",
    "-\t识别并提取最近一段语库中的关键主题\n",
    "\n",
    "\n",
    "-\t跟踪这些关键主题到目前为止如何发展：相关性，感知 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------ Get topics + historical analysis ----------------')\n",
    "\n",
    "payload = nucleus_api.TopicHistoryModel(dataset='Twitter_feed', \n",
    "                                    update_period='d', \n",
    "                                    query='',\n",
    "                                    num_topics=20, \n",
    "                                    num_keywords=8,\n",
    "                                    inc_step=1,\n",
    "                                    period_start=\"2018-12-01 00:00:00\",\n",
    "                                    period_end=\"2019-01-01 00:00:00\")\n",
    "try:\n",
    "    api_response = api_instance.post_topic_historical_analysis_api(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    print('Plotting historical metrics data...')\n",
    "    historical_metrics = []\n",
    "    for res in api_response.result:\n",
    "        # 构建历史度量的图表列表\n",
    "        historical_metrics.append({\n",
    "            'topic'    : res.keywords,\n",
    "            'time_stamps' : np.array(res.time_stamps),\n",
    "            'strength' : np.array(res.strengths, dtype=np.float32),\n",
    "            'consensus': np.array(res.consensuses, dtype=np.float32), \n",
    "            'sentiment': np.array(res.sentiments, dtype=np.float32)})\n",
    "\n",
    "    selected_topics = range(len(historical_metrics)) \n",
    "    nucleus_helper.topic_charts_historical(historical_metrics, selected_topics, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   对于与您相关的一些主题，请列出最近的主要内容（摘要，最佳来源）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get the summaries of recent topics in your feed --------------')\n",
    "\n",
    "payload = nucleus_api.TopicSummaryModel(dataset='Twitter_feed',                         \n",
    "                            query='',                       \n",
    "                            num_topics=20, \n",
    "                            num_keywords=8,\n",
    "                            period_start=\"2018-12-31 00:00:00\",\n",
    "                            period_end=\"2019-01-01 00:00:00\")\n",
    "try:\n",
    "    api_response = api_instance.post_topic_summary_api(payload)        \n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:    \n",
    "    for res in api_response.result:\n",
    "        print('Topic', i, 'summary:')\n",
    "        print('    Keywords:', res.topic)\n",
    "        for j in range(len(res.summary)):\n",
    "            print(res.summary[j])\n",
    "            print('    Document ID:', res.summary[j].sourceid)\n",
    "            print('        Title:', res.summary[j].title)\n",
    "            print('        Sentences:', res.summary[j].sentences)\n",
    "            print('        Author:', res.summary[j].attribute['author'])\n",
    "            print('        Time:', datetime.datetime.fromtimestamp(float(res.summary[j].attribute['time'])))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   您可以通过利用作者连接性分析深入了解一些有影响力的人或有趣的新兴贡献者：\n",
    "\n",
    "根据他们参与的主题和动机，谁与那个人最相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------- Get author connectivity -------------------')\n",
    "\n",
    "payload = nucleus_api.AuthorConnection(dataset='Twitter_feed', \n",
    "                                        target_author='Yann LeCun', \n",
    "                                        query='',\n",
    "                                        period_start=\"2018-12-31 00:00:00\",\n",
    "                                        period_end=\"2019-01-01 00:00:00\")\n",
    "try:\n",
    "    api_response = api_instance.post_author_connectivity_api(payload)    \n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    print('Mainstream connections:')\n",
    "    for mc in api_response.result.mainstream_connections:\n",
    "        print('    Topic:', mc.keywords)\n",
    "        print('    Authors:', \" \".join(str(x) for x in mc.authors))\n",
    "\n",
    "    print('Niche connections:')\n",
    "    for nc in api_response.result.niche_connections:\n",
    "        print('    Topic:', nc.keywords)\n",
    "        print('    Authors:', \" \".join(str(x) for x in nc.authors))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\t接下来，我们将讨论如何利用用户可用的不同参数来优化内容分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\t微调\n",
    "\n",
    "#### a.\t量身定制主题\n",
    "\n",
    "-   使用主题历史分析API中的`custom_stop_words`参数排除无关的关键字/主题以定制内容分析\n",
    "\n",
    "\n",
    "-\t提取语库中的关键主题并打印其关键字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------- Get the recent topics in your feed --------------')\n",
    "\n",
    "payload = nucleus_api.Topics(dataset='Twitter_feed',                         \n",
    "                            query='',                       \n",
    "                            num_topics=20, \n",
    "                            num_keywords=8,\n",
    "                            period_start=\"2018-12-31 00:00:00\",\n",
    "                            period_end=\"2019-01-01 00:00:00\")\n",
    "try:\n",
    "    api_response = api_instance.post_topic_api(payload)        \n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:    \n",
    "    for i, res in enumerate(api_response.result.topics):\n",
    "        print('Topic', i, ' keywords: ', res.keywords)    \n",
    "        print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，您可以通过创建`custom_stop_words`变量来定制内容分析。 如下所示，将初始化变量传递到第2节主代码的有效负载中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = [\"supervised learning\", \"training\"] # str | 停用词列表。 （可选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\t将内容分析集中在某些主题上\n",
    "如果您决定关注内容分析，例如深度学习主题，只需将第2节主代码中的查询变量替换为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(deep-learning OR LSTM OR RNN OR Neural network)' # str | Fulltext query, using mysql MATCH boolean query format. Example: \"(word1 OR word2) AND (word3 OR word4)\" (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\t探索文档类型，回顾期，提取的主题数量的影响\n",
    "**period_starts**: 您可以使用不同的回顾期执行内容分析。 您可以根据目标在相关时间范围内对数据进行切片。\n",
    "\n",
    "**Document types**: 您可以根据来源类型（例如，不同语言，来自学术界，私营部门或独立个人的贡献者）来调查主题及其随时间的演变如何变化。\n",
    "\n",
    " - 创建一个变量`metadata_selection`并将其传递给有效负载（如果使用您的文档或中央银行订阅源，新闻媒体RSS订阅源没有可以选择的元数据）。\n",
    " \n",
    " - 在整个语库的子集上重新运行第2节的主要代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_selection = {\"category\": \"Academia\"}   # str | json object of {\\\"metadata_field\\\":[\\\"selected_values\\\"]} (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\t下一步\n",
    "-\t可能的扩展：构建一个内部BI报告，提取主要主题和关键内容\n",
    "\n",
    "\n",
    "-\t可能的扩展：比较内部和外部的专家团队讨论，激发市场竞争性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "版权(c) 2019年 SumUp Analytics 公司 版权所有。 \n",
    "\n",
    "通知：所有信息均属于SumUp Analytics Inc公司及其供应商的财产。 本合同所包含的知识产权和技术概念属于SumUp Analytics Inc.及其供应商的专利，可由美国和外国专利、在工艺中的专利以及受贸易秘密或版权法保护的专利涵盖。 \n",
    "\n",
    "除非得到SumUp Analytics公司的事先书面批准，否则严禁传播此类信息或复制此材料。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
