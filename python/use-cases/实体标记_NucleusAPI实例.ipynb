{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>  实体标记 -  Nucleus API实例</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  所有权及保密条款属SumUp Analytics所有</center></h1>\n",
    "\n",
    "\n",
    "<h1><center>  免责声明和服务条款可通过 www.sumup.ai 获取</center></h1>\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## 目标:\n",
    "-\t在给定a-prioris列表的情况下，使用在给定数据集的每个文档中找到的实体生成元数据\n",
    "\n",
    "\n",
    "## 数据:\n",
    "-\t任何文件集合\n",
    "\n",
    "-   在你感兴趣的数据集中检测和标记的实体列表\n",
    "\n",
    "\n",
    "## Nucleus APIs used:\n",
    "-\t数据集创建 API\n",
    " - \t*api_instance.post_upload_file(file, dataset)*\n",
    " - \t*nucleus_helper.import_files(api_instance, dataset, file_iters, processes=1)*\n",
    "\n",
    "        nucleus_helper.import_files利用api_instance.post_upload_file并行执行来加速数据集的创建\n",
    "\n",
    "\n",
    "-\t数据集标记 API\n",
    " - \t*api_instance.post_dataset_tagging(payload)*\n",
    "\n",
    "\n",
    "-\t文件信息 API\n",
    " - \t*api_instance.post_doc_info(payload)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法:\n",
    "\n",
    "### 1.\t数据集准备\n",
    "-\t创建一个Nucleus数据集，其中包含所选历史时期内的所有相关文档\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import nucleus_api.api.nucleus_api as nucleus_helper\n",
    "import nucleus_api\n",
    "from nucleus_api.rest import ApiException\n",
    "\n",
    "configuration = nucleus_api.Configuration()\n",
    "configuration.host = 'UPDATE-WITH-API-SERVER-HOSTNAME'\n",
    "configuration.api_key['x-api-key'] = 'UPDATE-WITH-API-KEY'\n",
    "\n",
    "# 创建API实例\n",
    "api_instance = nucleus_api.NucleusApi(nucleus_api.ApiClient(configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---- Upload documents from a local folder into a new Nucleus dataset ----')\n",
    "folder = 'Corporate_documents'         \n",
    "dataset = 'Corporate_docs'# str | 文件的目标数据集。\n",
    "\n",
    "# 以递归方式从文件夹构建文件。 \n",
    "# 每项都采用以下格式\n",
    "# {'filename': filename,   # 要上传的文件名。 必填\n",
    "#  'metadata': {           # 该文件的元数据。 可选\n",
    "#      'key1': val1,       # 只要名称，密钥就可以有任意名称\n",
    "#      'key2': val2        # 包含字母数字（0-9 | a-z | A-Z）和下划线（_）\n",
    "#   } \n",
    "# }\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        #if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "        file_dict = {'filename': os.path.join(root, file),\n",
    "                     'metadata': {'category': 'News'}} # 没有每个新闻的代码，让我们标记它们\n",
    "        file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\t数据集标记\n",
    "-\t定义公司代码（或与您相关的任何其他实体）的列表\n",
    "\n",
    "\n",
    "-\t遍历此列表并使用数据集标记API来确定哪些文档包含给定的代码\n",
    "\n",
    "\n",
    "-\t接下来，我们将讨论如何构建自定义的停用词列表以优化文档摘要\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------- Tag dataset ------------------------')\n",
    "\n",
    "payload = nucleus_api.DatasetTaggingModel(dataset='Corporate_docs', \n",
    "                                    query='AAPL OR Apple', \n",
    "                                    metadata_selection='', \n",
    "                                    time_period='')\n",
    "try:\n",
    "    api_response = api_instance.post_dataset_tagging(payload)\n",
    "    api_ok = True\n",
    "except ApiException as e:\n",
    "    api_error = json.loads(e.body)\n",
    "    print('ERROR:', api_error['message'])\n",
    "    api_ok = False\n",
    "\n",
    "if api_ok:\n",
    "    print('Information about dataset', dataset)\n",
    "    print('    Entity Tagged:', api_response.result.entities_tagged)\n",
    "    print('    Docids tagged with Entity:', api_response.result.doc_ids)\n",
    "    print('    Entity occurrences in each docid:', api_response.result.entities_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们创建实体列表并遍历它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [['AAPL', 'Apple'], ['GOOG', 'Google', 'Alphabet']]\n",
    "\n",
    "docs_tagged = []\n",
    "entities_tagged = []\n",
    "for i in range(len(entities)):\n",
    "    query = \" OR \".join(entities[i])\n",
    "    payload = nucleus_api.DatasetTaggingModel(dataset='Corporate_docs', \n",
    "                                    query=query, \n",
    "                                    metadata_selection='', \n",
    "                                    time_period='')\n",
    "    try:\n",
    "        api_response = api_instance.post_dataset_tagging(payload)\n",
    "        api_ok = True\n",
    "    except ApiException as e:\n",
    "        api_error = json.loads(e.body)\n",
    "        print('ERROR:', api_error['message'])\n",
    "        api_ok = False\n",
    "\n",
    "    if api_ok:\n",
    "        for docid in api_response['doc_ids']::\n",
    "            docs_tagged.append(docid)\n",
    "            entities_tagged.append(api_response['entities_tagged'][0]) # 保留实体的第一个命名作为标签\n",
    "\n",
    "        # 让我们重新组合每个文档标记的实体，这样我们就有了一个唯一的docid列表以及标记在其中的所有实体\n",
    "\n",
    "        # 此表对于生成带有作为元数据提供的代码的更新数据集非常有用，因为我们真正关心的是文件名而不是docids\n",
    "        from collections import defaultdict\n",
    "        d = defaultdict(list)\n",
    "        for i, entity in enumerate(entities_tagged):\n",
    "            payload = nucleus_api.DocInfo(\n",
    "                dataset='Corporate_docs', \n",
    "                doc_ids=docs_tagged[i],\n",
    "                metadata_selection='')\n",
    "            api_response = api_instance.post_doc_info(payload)\n",
    "            key = api_response.result[0].attribute['filename']\n",
    "            d[key].append(entity)\n",
    "        d = dict(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这些标签，我们可以构建第二个额外元数据的数据集，这在信号研究和合规性分析中非常方便。\n",
    "\n",
    "我们可以使用文件名将原始文档与已标记的文档进行匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Corporate_docs_2'# str | 文件的目标数据集。\n",
    "\n",
    "file_iter = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        #if Path(file).suffix == '.pdf': # .txt .doc .docx .rtf .html .csv also supported\n",
    "        \n",
    "        # 我们知道当前正在注入的文件的文件名，我们可以将它与标记文档表进行匹配\n",
    "        if d[os.path.join(root, file)] != [] # 仅使用具有标记实体的文档构建新数据集\n",
    "            tickers = d[os.path.join(root, file)]\n",
    "            file_dict = {'filename': os.path.join(root, file),\n",
    "                         'metadata': {'companies': tickers,\n",
    "                                      'category': 'News'}}\n",
    "            \n",
    "            file_iter.append(file_dict)\n",
    "\n",
    "file_props = nucleus_helper.upload_files(api_instance, dataset, file_iter, processes=4)\n",
    "for fp in file_props:\n",
    "    print(fp.filename, '(', fp.size, 'bytes) has been added to dataset', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\t微调\n",
    "\n",
    "#### a.\t扩展给定实体的同义词列表\n",
    "**query**: 您可以优化数据集标记并扩展您的代码列表（或其他相关实体）以包含任意数量的备选方案。 \n",
    "\n",
    "您还可以创建一次保守的超集列表，保留该列表并将其重新用于您要标记的每个数据集。\n",
    "\n",
    "上述也适用与外国公司。 例如，您可以将列表的条目定义为['Nintendo'，'NTDOY'，'任天堂株式会社']\n",
    "\n",
    "将该扩展列表（循环遍历所有不同的代码）传递给第2节主代码中的查询参数，然后重新运行该代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [['AAPL', 'Apple', 'iPhone'], ['GOOG', 'Google', 'Alphabet', 'Android'], ['NTDOY', 'Nintendo', '任天堂株式会社']]\n",
    "\n",
    "docs_tagged = []\n",
    "entities_tagged = []\n",
    "for i in range(len(entities)):\n",
    "    query = \" OR \".join(entities[i])\n",
    "    payload = nucleus_api.DatasetTaggingModel(dataset='Corporate_docs', \n",
    "                                    query=query, \n",
    "                                    metadata_selection='', \n",
    "                                    time_period='')\n",
    "    try:\n",
    "        api_response = api_instance.post_dataset_tagging(payload)\n",
    "        api_ok = True\n",
    "    except ApiException as e:\n",
    "        api_error = json.loads(e.body)\n",
    "        print('ERROR:', api_error['message'])\n",
    "        api_ok = False\n",
    "\n",
    "    if api_ok:\n",
    "        for docid in api_response['doc_ids']:\n",
    "            docs_tagged.append(docid)\n",
    "            entities_tagged.append(api_response['entities_tagged'][0]) # 保留实体的第一个命名作为标签\n",
    "            \n",
    "        # 我们重新组合每个文档标记的实体，这样我们就有了一个唯一的docid列表以及标记在其中的所有实体\n",
    "        # 此表对于生成更新的数据集非常有用，因此我们真正关心的是文件名而不是docids\n",
    "        d = defaultdict(list)\n",
    "        for i, entity in enumerate(entities_tagged):\n",
    "            payload = nucleus_api.DocInfo(\n",
    "                dataset='Corporate_docs', \n",
    "                doc_ids=docs_tagged[i],\n",
    "                metadata_selection='')\n",
    "            api_response = api_instance.post_doc_info(payload)\n",
    "            key = api_response.result[0].attribute['filename']\n",
    "            d[key].append(entity)\n",
    "        d = dict(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "版权(c) 2019年 SumUp Analytics 公司 版权所有。 \n",
    "\n",
    "通知：所有信息均属于SumUp Analytics Inc公司及其供应商的财产。 本合同所包含的知识产权和技术概念属于SumUp Analytics Inc.及其供应商的专利，可由美国和外国专利、在工艺中的专利以及受贸易秘密或版权法保护的专利涵盖。 \n",
    "\n",
    "除非得到SumUp Analytics公司的事先书面批准，否则严禁传播此类信息或复制此材料。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
